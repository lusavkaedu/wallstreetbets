{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713e2b95",
   "metadata": {},
   "source": [
    "# Identifying Precise Forecasters on r/Wallstreetbets\n",
    "**BrainStation Data Science Bootcamp - Capstone Project**\n",
    "\n",
    "**Author: L Gavrilova**\n",
    "\n",
    "**Date: 6 November 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8905b9",
   "metadata": {},
   "source": [
    "# Notebook 2B - Reddit datasets - Text Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e991fd",
   "metadata": {},
   "source": [
    "## 2.0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook is a close copy of the notebook for cleaning the labelled dataset. \n",
    "\n",
    "In this notebook 2B I perform the following steps:\n",
    "\n",
    "1. I load the reddit dataset and repeat all the same cleaning steps that I designed for cleaning the labelled dataset (removing website links, removing and preserving emojis, applying WSB dictionary, empty spaces removal, etc). \n",
    "2. I merged the 'title' and 'selftext' fields from the reddit dataset into one new column named 'text'.  This is done to simplify processing (to process one column, instead of two). Moreover, in nearly 30% of rows 'selftext' has missing value, whereas 'title' column had no missing values.  It made sense to combine these two columns as they carry no significant difference in meaning or significance. \n",
    "\n",
    "The result is a csv file that is prepared for further machine processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f51324",
   "metadata": {},
   "source": [
    "### 2.1.1. Data Loading and Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e553e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Regular Expressions Library\n",
    "import re\n",
    "\n",
    "# Emoji Handling Library\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/reddit_cleaned_slim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1260374 entries, 0 to 1260373\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   id                   1260374 non-null  object \n",
      " 1   author               1260374 non-null  object \n",
      " 2   created              1260374 non-null  object \n",
      " 3   removed              1260374 non-null  int64  \n",
      " 4   deleted              1260374 non-null  int64  \n",
      " 5   is_self              1260374 non-null  int64  \n",
      " 6   is_video             1260374 non-null  int64  \n",
      " 7   title                1260370 non-null  object \n",
      " 8   link_flair_text      1260374 non-null  object \n",
      " 9   upvote_ratio         1260374 non-null  float64\n",
      " 10  score                1260374 non-null  int64  \n",
      " 11  num_comments         1260374 non-null  int64  \n",
      " 12  selftext             831960 non-null   object \n",
      " 13  shortlink            1260374 non-null  object \n",
      " 14  FolderName           1260374 non-null  object \n",
      " 15  word_count_selftext  1260374 non-null  int64  \n",
      " 16  word_count_title     1260374 non-null  int64  \n",
      " 17  date                 1260374 non-null  object \n",
      "dtypes: float64(1), int64(8), object(9)\n",
      "memory usage: 173.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created</th>\n",
       "      <th>removed</th>\n",
       "      <th>deleted</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_video</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>shortlink</th>\n",
       "      <th>FolderName</th>\n",
       "      <th>word_count_selftext</th>\n",
       "      <th>word_count_title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>938010</th>\n",
       "      <td>l3fj6c</td>\n",
       "      <td>seanieboi66</td>\n",
       "      <td>2021-01-23 16:44:45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My first big win in Trading. Saw I had a retur...</td>\n",
       "      <td>Gain</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://redd.it/l3fj6c</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647104</th>\n",
       "      <td>mekli5</td>\n",
       "      <td>bmanvg21</td>\n",
       "      <td>2021-03-27 19:20:46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BIDU, CMCSA, RIDE</td>\n",
       "      <td>none</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://redd.it/mekli5</td>\n",
       "      <td>options</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697697</th>\n",
       "      <td>p4t36t</td>\n",
       "      <td>CherryManhattan</td>\n",
       "      <td>2021-08-15 13:07:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Will this whole Taliban thing affect our markets?</td>\n",
       "      <td>none</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://redd.it/p4t36t</td>\n",
       "      <td>investing</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866190</th>\n",
       "      <td>lonwom</td>\n",
       "      <td>Bcl3018</td>\n",
       "      <td>2021-02-21 03:27:14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Btcy . Biotricity small float, in the mobile t...</td>\n",
       "      <td>DD/Research</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://redd.it/lonwom</td>\n",
       "      <td>robinhoodpennystocks</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401062</th>\n",
       "      <td>makh1e</td>\n",
       "      <td>pezza31</td>\n",
       "      <td>2021-03-22 10:41:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anyone else enjoy collecting GME stock?! Colle...</td>\n",
       "      <td>News</td>\n",
       "      <td>0.97</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://redd.it/makh1e</td>\n",
       "      <td>gme</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2021-03-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           author              created  removed  deleted  \\\n",
       "938010  l3fj6c      seanieboi66  2021-01-23 16:44:45        1        0   \n",
       "647104  mekli5         bmanvg21  2021-03-27 19:20:46        1        0   \n",
       "697697  p4t36t  CherryManhattan  2021-08-15 13:07:20        1        0   \n",
       "866190  lonwom          Bcl3018  2021-02-21 03:27:14        1        0   \n",
       "401062  makh1e          pezza31  2021-03-22 10:41:14        0        0   \n",
       "\n",
       "        is_self  is_video                                              title  \\\n",
       "938010        0         0  My first big win in Trading. Saw I had a retur...   \n",
       "647104        1         0                                  BIDU, CMCSA, RIDE   \n",
       "697697        1         0  Will this whole Taliban thing affect our markets?   \n",
       "866190        1         0  Btcy . Biotricity small float, in the mobile t...   \n",
       "401062        0         0  Anyone else enjoy collecting GME stock?! Colle...   \n",
       "\n",
       "       link_flair_text  upvote_ratio  score  num_comments   selftext  \\\n",
       "938010            Gain          1.00      1             0        NaN   \n",
       "647104            none          1.00      1             1  [removed]   \n",
       "697697            none          1.00      1             1  [removed]   \n",
       "866190     DD/Research          0.66      1             0  [removed]   \n",
       "401062            News          0.97     98             2        NaN   \n",
       "\n",
       "                     shortlink            FolderName  word_count_selftext  \\\n",
       "938010  https://redd.it/l3fj6c        wallstreetbets                    1   \n",
       "647104  https://redd.it/mekli5               options                    1   \n",
       "697697  https://redd.it/p4t36t             investing                    1   \n",
       "866190  https://redd.it/lonwom  robinhoodpennystocks                    1   \n",
       "401062  https://redd.it/makh1e                   gme                    1   \n",
       "\n",
       "        word_count_title        date  \n",
       "938010                22  2021-01-23  \n",
       "647104                 3  2021-03-27  \n",
       "697697                 8  2021-08-15  \n",
       "866190                23  2021-02-21  \n",
       "401062                12  2021-03-22  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].nunique() == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0.000000\n",
       "author                 0.000000\n",
       "created                0.000000\n",
       "removed                0.000000\n",
       "deleted                0.000000\n",
       "is_self                0.000000\n",
       "is_video               0.000000\n",
       "title                  0.000003\n",
       "link_flair_text        0.000000\n",
       "upvote_ratio           0.000000\n",
       "score                  0.000000\n",
       "num_comments           0.000000\n",
       "selftext               0.339910\n",
       "shortlink              0.000000\n",
       "FolderName             0.000000\n",
       "word_count_selftext    0.000000\n",
       "word_count_title       0.000000\n",
       "date                   0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'title_selftext': 4\n"
     ]
    }
   ],
   "source": [
    "# Concatenate 'title' and 'selftext' into a new column 'title_selftext'\n",
    "df_clean['Text'] = df_clean['title'] + ' ' + df_clean['selftext'].fillna('')\n",
    "\n",
    "# Check for missing values in the new 'title_selftext' column\n",
    "missing_values = df_clean['Text'].isnull().sum()\n",
    "\n",
    "# Print the number of missing values\n",
    "print(f\"Number of missing values in 'title_selftext': {missing_values}\")\n",
    "\n",
    "# Drop the legacy columns 'selftext' and 'title'\n",
    "df_clean = df_clean.drop(columns=['title', 'selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def purge_content(text):\n",
    "    if pd.isna(text):\n",
    "        return text  # Return NaN as it is\n",
    "    text_without_urls = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text_without_hashtags = re.sub(r'#\\S+', '', text_without_urls)\n",
    "    text_without_mentions = re.sub(r'@\\S+', '', text_without_hashtags)\n",
    "    text_without_linebreaks = re.sub(r'\\n+', '', text_without_mentions)\n",
    "    clean_text = re.sub(r'\\n+', ' ', text_without_linebreaks)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Use the apply function to clean the 'selftext' column\n",
    "df_clean.loc[:, 'Text'] = df_clean['Text'].apply(purge_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created</th>\n",
       "      <th>removed</th>\n",
       "      <th>deleted</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_video</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>shortlink</th>\n",
       "      <th>FolderName</th>\n",
       "      <th>word_count_selftext</th>\n",
       "      <th>word_count_title</th>\n",
       "      <th>date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, author, created, removed, deleted, is_self, is_video, link_flair_text, upvote_ratio, score, num_comments, shortlink, FolderName, word_count_selftext, word_count_title, date, Text]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "df_clean[df_clean['Text'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where the 'Text' column is an empty string\n",
    "df_clean = df_clean[df_clean['Text'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created</th>\n",
       "      <th>removed</th>\n",
       "      <th>deleted</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_video</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>shortlink</th>\n",
       "      <th>FolderName</th>\n",
       "      <th>word_count_selftext</th>\n",
       "      <th>word_count_title</th>\n",
       "      <th>date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252377</th>\n",
       "      <td>lc842f</td>\n",
       "      <td>Redlink44</td>\n",
       "      <td>2021-02-04 05:03:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>0.83</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>https://redd.it/lc842f</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>The Ultimate FUD Theyve bought out the sub. Theyre buying the narrative. This is sus af. Wheres all the DD gone recently?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     author              created  removed  deleted  is_self  \\\n",
       "252377  lc842f  Redlink44  2021-02-04 05:03:20        0        0        1   \n",
       "\n",
       "        is_video link_flair_text  upvote_ratio  score  num_comments  \\\n",
       "252377         0      Discussion          0.83     33             7   \n",
       "\n",
       "                     shortlink      FolderName  word_count_selftext  \\\n",
       "252377  https://redd.it/lc842f  wallstreetbets                   19   \n",
       "\n",
       "        word_count_title        date  \\\n",
       "252377                 3  2021-02-04   \n",
       "\n",
       "                                                                                                                             Text  \n",
       "252377  The Ultimate FUD Theyve bought out the sub. Theyre buying the narrative. This is sus af. Wheres all the DD gone recently?  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link_flair_text\n",
       "Discussion                                             287149\n",
       "none                                                   159642\n",
       "YOLO                                                   120533\n",
       "Meme                                                   119372\n",
       "Gain                                                    64313\n",
       "DD                                                      41598\n",
       "💎🙌                                                      35460\n",
       "Loss                                                    30419\n",
       "Shitpost                                                24699\n",
       "💎 🙌                                                     19587\n",
       "🐵 Discussion 💬                                          16968\n",
       "☁️ Fluff  🍌                                             14872\n",
       "😂 Memes 😹                                               14691\n",
       "Fluff                                                   11760\n",
       "Hedge Fund Tears                                         9202\n",
       "Memes 🤣                                                  8885\n",
       "Memes                                                    8474\n",
       "General Discussion                                       6472\n",
       "Discussion 🦍                                             3748\n",
       "Stock Info :stonk:                                       3681\n",
       "Shitpost 🎱                                               3600\n",
       "Company Discussion                                       3329\n",
       "🔬 DD 📊                                                   3286\n",
       "Catalyst                                                 3171\n",
       "DD :DD:                                                  3107\n",
       "Memes 😹                                                  2838\n",
       ":snoo_feelsgoodman: General Discussion :disscusion:      2689\n",
       ":snoo_thoughtful: Question :Question:                    2670\n",
       "Newbie                                                   2559\n",
       "Fluff 🍌                                                  2518\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting unique values\n",
    "top_20_flairs = df_clean['link_flair_text'].value_counts().head(30)\n",
    "top_20_flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103506, 17)\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where 'link_flair_text' is irrelevant\n",
    "\n",
    "# List of irrelevant flair texts\n",
    "irrelevant_flairs = ['Credit', 'Taxes', 'Market News & Analysis', 'Chart', 'Other', '📰 News | Media 📱', 'Question 🙋‍♂️','Technical Analysis', 'Housing', 'Retirement', 'Question','Planning', 'Saving', 'News', 'Help Needed', 'Debt', 'Auto', 'Employment', 'Insurance', \"Budgeting\", \"Advice\", 'Advice Request', ':Filing: New Filing :Filing:', 'Trash - Cool story', 'Question :Question:']\n",
    "\n",
    "# Filter out rows where 'link_flair_text' is in the list of irrelevant flairs\n",
    "df_clean = df_clean[~df_clean['link_flair_text'].isin(irrelevant_flairs)].copy()\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created</th>\n",
       "      <th>removed</th>\n",
       "      <th>deleted</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_video</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>shortlink</th>\n",
       "      <th>FolderName</th>\n",
       "      <th>word_count_selftext</th>\n",
       "      <th>word_count_title</th>\n",
       "      <th>date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950547</th>\n",
       "      <td>mupty7</td>\n",
       "      <td>iiDRUMCOREii</td>\n",
       "      <td>2021-04-20 13:03:59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Memes 😹</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>https://redd.it/mupty7</td>\n",
       "      <td>gme</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>I AM JACKED TO THE TITS! Happy Tuesday apes! I hope your day is starting off well! Enjoy a morale post 🚀💎🙌🦍</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        author              created  removed  deleted  is_self  \\\n",
       "950547  mupty7  iiDRUMCOREii  2021-04-20 13:03:59        0        0        0   \n",
       "\n",
       "        is_video link_flair_text  upvote_ratio  score  num_comments  \\\n",
       "950547         1         Memes 😹          0.95     20             0   \n",
       "\n",
       "                     shortlink FolderName  word_count_selftext  \\\n",
       "950547  https://redd.it/mupty7        gme                    1   \n",
       "\n",
       "        word_count_title        date  \\\n",
       "950547                22  2021-04-20   \n",
       "\n",
       "                                                                                                                Text  \n",
       "950547  I AM JACKED TO THE TITS! Happy Tuesday apes! I hope your day is starting off well! Enjoy a morale post 🚀💎🙌🦍   "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording the cleaned dataset as a new csv file to be used in other notebooks:\n",
    "# Save the DataFrame to a CSV file\n",
    "df_clean.to_csv('../data/02_reddit_cleaned_slim.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b4226",
   "metadata": {},
   "source": [
    "### 2.1.2. Filtering out emojis by creating a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e983b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map emojis to their descriptions\n",
    "def emoji_description(emoji):\n",
    "    emoji_map = {\n",
    "        \"🚀\": \" super optimistic, \",\n",
    "        \"🦍\": \" brotherhood, \",\n",
    "        \"🤞\": \" hope, \",\n",
    "        \"🌙\": \" very optimistic, \",\n",
    "        \"🌕\": \" very optimistic, \",\n",
    "        \"💎🤚🏼\": \" patient investors, \",\n",
    "        \"💎🖐\": \" patient investors, \",\n",
    "        \"💎🙌\": \" patient investors, \",\n",
    "        \"🙌\": \" patient investors, \",\n",
    "        \"💎\": \" patient investors, \",\n",
    "        \"🧻🤚🏼\": \" impatient investors, \",\n",
    "        \"🧻🖐\": \" impatient investors, \",\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "    # If the full emoji is in the map, return the description\n",
    "    if emoji in emoji_map:\n",
    "        return emoji_map[emoji]\n",
    "    # If not, split any combined emojis and look up their individual descriptions\n",
    "    else:\n",
    "        return ''.join([emoji_map.get(char, '') for char in emoji])  # Default to empty string if not in mapping\n",
    "\n",
    "def extract_and_replace_emojis(df, text_column_name='Text', emoji_column_name='emoji_text'):\n",
    "    # Initialize an empty column for extracted emojis if a column name is provided\n",
    "    if emoji_column_name:\n",
    "        df[emoji_column_name] = ''\n",
    "\n",
    "    # Function to extract and replace emojis in a text\n",
    "    def process_text(text):\n",
    "        emoji_pattern = re.compile(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FB00-\\U0001FBFF\\U0001F004]+')\n",
    "\n",
    "        # Find all emojis in the text using the regex pattern\n",
    "        emoji_matches = emoji_pattern.findall(text)\n",
    "        emojis_extracted = ''\n",
    "        text_with_replaced_emojis = text\n",
    "\n",
    "        # Iterate over the found emojis\n",
    "        for emoji_str in emoji_matches:\n",
    "            # For each emoji in the emoji string\n",
    "            for emoji_char in emoji_str:\n",
    "                emoji_desc = emoji_description(emoji_char)  # Get description for individual emoji\n",
    "                text_with_replaced_emojis = text_with_replaced_emojis.replace(emoji_char, emoji_desc, 1)\n",
    "                emojis_extracted += emoji_char + ' '  # Add space to separate emojis\n",
    "\n",
    "        # Return the modified text and the extracted emojis\n",
    "        return text_with_replaced_emojis, emojis_extracted.strip()\n",
    "\n",
    "    # Apply the processing function to the specified column and create new columns for text and emojis\n",
    "    result = df[text_column_name].apply(process_text)\n",
    "    df[text_column_name] = result.apply(lambda x: x[0])\n",
    "    \n",
    "    if emoji_column_name:\n",
    "        df[emoji_column_name] = result.apply(lambda x: x[1])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7c98bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to extract and replace emojis from 'Text' column\n",
    "df_clean = df_clean.copy()\n",
    "df_clean = extract_and_replace_emojis(df_clean, text_column_name='text', emoji_column_name='emoji_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4be45fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emoji_text\n",
       "                                           118163\n",
       "🚀 🚀 🚀                                        3202\n",
       "🚀                                            2139\n",
       "🚀 🚀 🚀 🚀                                      1311\n",
       "🚀 🚀                                          1185\n",
       "                                            ...  \n",
       "💲 💎 💎                                           1\n",
       "🤤 💎 💎 🚀 🚀 🚀                                     1\n",
       "🌖 🦧 🍌 🚀 💎 🙌                                     1\n",
       "💎 💎 💎 💎 💎 💎 🙏 🏼 🙏 🏼 🙏 🏼 🙏 🏼 💎 💎 💎 💎 💎 💎         1\n",
       "🥝 🚀 🚀 🚀                                         1\n",
       "Name: count, Length: 12881, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the new column with emojis extracted from the text\n",
    "df_clean.sample().T\n",
    "df_clean['emoji_text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Replacing slang with a custom made \"WSB Dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WSB lingo dictionary\n",
    "wsb_dict_df = pd.read_csv('../data/WSB_dictionary.csv')\n",
    "\n",
    "# Convert the DataFrame to a dictionary\n",
    "wsb_dict = dict(zip(wsb_dict_df['WSB lingo'], wsb_dict_df['English']))\n",
    "\n",
    "# Function to replace WSB lingo with English\n",
    "def replace_wsb_lingo(text):\n",
    "    # Use a regex pattern to match only whole words\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(key) for key in wsb_dict.keys()) + r')\\b'\n",
    "    # Replace occurrences of each lingo with the English equivalent\n",
    "    return re.sub(pattern, lambda x: wsb_dict[x.group()], text)\n",
    "\n",
    "# Apply the function to the 'Text' column\n",
    "df_clean['text'] = df_clean['text'].apply(replace_wsb_lingo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Examples of texts before and after the cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                                lb2mfm\n",
      "author                                                                    scott_doge_wow\n",
      "created                                                              2021-02-02 18:26:07\n",
      "removed                                                                                1\n",
      "deleted                                                                                0\n",
      "is_self                                                                                0\n",
      "is_video                                                                               0\n",
      "title                  My friend got his boomer mom to buy some $GME. 💎🤲 ANYONE CAN HOLD\n",
      "link_flair_text                                                                     YOLO\n",
      "upvote_ratio                                                                        0.96\n",
      "score                                                                               7993\n",
      "num_comments                                                                         253\n",
      "selftext                                                                             NaN\n",
      "shortlink                                                         https://redd.it/lb2mfm\n",
      "FolderName                                                                wallstreetbets\n",
      "word_count_selftext                                                                    1\n",
      "word_count_title                                                                      14\n",
      "date                                                                          2021-02-02\n",
      "Name: 2026, dtype: object\n",
      "id                                                                                                   lb2mfm\n",
      "author                                                                                       scott_doge_wow\n",
      "created                                                                                 2021-02-02 18:26:07\n",
      "removed                                                                                                   1\n",
      "deleted                                                                                                   0\n",
      "is_self                                                                                                   0\n",
      "is_video                                                                                                  0\n",
      "link_flair_text                                                                                        YOLO\n",
      "upvote_ratio                                                                                           0.96\n",
      "score                                                                                                  7993\n",
      "num_comments                                                                                            253\n",
      "shortlink                                                                            https://redd.it/lb2mfm\n",
      "FolderName                                                                                   wallstreetbets\n",
      "word_count_selftext                                                                                       1\n",
      "word_count_title                                                                                         14\n",
      "date                                                                                             2021-02-02\n",
      "text                   My friend got his boomer mom to buy some $GME.  patient investors,  ANYONE CAN HOLD \n",
      "emoji_text                                                                                              💎 🤲\n",
      "Name: 2026, dtype: object\n"
     ]
    }
   ],
   "source": [
    "original_with_index = df.loc[2026]\n",
    "print(original_with_index)\n",
    "\n",
    "clean_with_index = df_clean.loc[2026]\n",
    "print(clean_with_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                     l8wp15\n",
      "author                                             davidr2448\n",
      "created                                   2021-01-30 21:52:05\n",
      "removed                                                     0\n",
      "deleted                                                     0\n",
      "is_self                                                     0\n",
      "is_video                                                    1\n",
      "title                  Current Situation 😂📈🚀🍿🔥 $GME $AMC $NOK\n",
      "link_flair_text                                          none\n",
      "upvote_ratio                                             0.98\n",
      "score                                                    1125\n",
      "num_comments                                              156\n",
      "selftext                                                  NaN\n",
      "shortlink                              https://redd.it/l8wp15\n",
      "FolderName                                                gme\n",
      "word_count_selftext                                         1\n",
      "word_count_title                                            6\n",
      "date                                               2021-01-30\n",
      "Name: 3386, dtype: object\n",
      "id                                                                    l8wp15\n",
      "author                                                            davidr2448\n",
      "created                                                  2021-01-30 21:52:05\n",
      "removed                                                                    0\n",
      "deleted                                                                    0\n",
      "is_self                                                                    0\n",
      "is_video                                                                   1\n",
      "link_flair_text                                                         none\n",
      "upvote_ratio                                                            0.98\n",
      "score                                                                   1125\n",
      "num_comments                                                             156\n",
      "shortlink                                             https://redd.it/l8wp15\n",
      "FolderName                                                               gme\n",
      "word_count_selftext                                                        1\n",
      "word_count_title                                                           6\n",
      "date                                                              2021-01-30\n",
      "text                   Current Situation  super optimistic,  $GME $AMC $NOK \n",
      "emoji_text                                                         😂 📈 🚀 🍿 🔥\n",
      "Name: 3386, dtype: object\n"
     ]
    }
   ],
   "source": [
    "original_with_index = df.loc[3386]\n",
    "print(original_with_index)\n",
    "\n",
    "clean_with_index = df_clean.loc[3386]\n",
    "print(clean_with_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d8ec9",
   "metadata": {},
   "source": [
    "## 2.2. Exporting the cleaned dataset into .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording the cleaned dataset as a new csv file to be used in future:\n",
    "# Save the DataFrame to a CSV file\n",
    "df_clean.to_csv('../data/02_reddit_GMEonly_wo_emoji.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
