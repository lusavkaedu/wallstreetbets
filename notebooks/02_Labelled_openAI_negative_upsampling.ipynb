{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project \n",
    "\n",
    "**BrainStation Data Science Bootcamp - Machine Learning Project**\n",
    "\n",
    "**Author: L Gavrilova**\n",
    "\n",
    "**Date: 20 November 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2. Negative Labels Upsampling using OpenAI API  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My EDA of the labelled dataset described in the Notebook 1 highlighted a serious shortage of the negatively labelled comments/messages (only 1.6% of the data).  When I tried to run my modelling using such deeply imbalanced dataset I wasn’t getting good results on recall and precision for a minority class. Therefore, **I decided to use open Ai’s GPT models as a substitute for human labelling**.  I used GPT 3.5 as a first labeller, and then I used GPT-4 model as a second \"pair of eyes\", so to say, to label my dataset. The process is detailed in this notebook in the code below, and it can be summarised as follows: \n",
    "\n",
    "1. I used a large dataset of Reddit WallStreetBets posts from 2021 as my source of text/posts.  The dataset is described in detail in my project Notebook 4. In short, it is a large dataset of finance related subreddits posts collected in 2021.  The source of the dataset is here: https://www.kaggle.com/datasets/leukipp/reddit-finance-data.  See my Notebook 4 for a full description.  I will refer to this dataset as \"the Reddit dataset\" throughout my notebooks (to distinguish it from the small “labelled dataset” described in the Notebook 1). \n",
    "\n",
    "2. I loaded the Reddit dataset and filtered out those rows that has empty text fields, too long and too short messages, and concentrated on the period after March 2021, when the bullishness that prevailed in 1Q 2021 has somewhat subsided. I thought that probability of finding negative/bearish messages was higher once we exclude an extremely bullish period of Q1 2021. \n",
    "\n",
    "3. I selected a portion of the large Reddit dataset to send to OpenAI API accompanied with a prompt to rate it as expressing bullish or bearish views on securities. \n",
    "\n",
    "4. I collected GPT 3.5 responses and filtered out all but negatively rated messages.  \n",
    "\n",
    "5. I then fed the negative only messages to GPT 4 model, using the same prompt, and collected its ratings. \n",
    "\n",
    "6. I kept only those messages where both models \"agreed\" that the message was bearish/negative with respect to the securities mentioned in its text. \n",
    "\n",
    "The final result of this process was saved as a CSV file. \n",
    "\n",
    "The table below describes the process in detail:\n",
    "\n",
    "| Description | Rows after this step | % of starting rows kept | % of starting rows deleted at this step |\n",
    "|-------------|----------------------:|-----------------------:|---------------------------------------:|\n",
    "| Data load | 1,260,374 | 100.00% | |\n",
    "| rows where 'link_flair_text' is irrelevant | 1,246,161 | 98.87% | -1.1% |\n",
    "| rows where 'title' starts with 'Daily ' | 1,245,087 | 98.79% | -0.1% |\n",
    "| rows where 'selftext' is '[removed]' | 618,703 | 49.09% | -49.7% |\n",
    "| rows where 'date' is before April 1, 2021 | 256,656 | 20.36% | -28.7% |\n",
    "| rows where token_count is greater than 400 | 241,354 | 19.15% | -1.2% |\n",
    "| rows where token_count is smaller than 20 | 111,183 | 8.82% | -10.3% |\n",
    "| some rows processed with Chat GPT 3.5 API | 3,648 | 0.29% | -8.5% |\n",
    "| only \"Negative\" ratings fed back to GPT 4 | 725 | 0.06% | -0.2% |\n",
    "| rows where both GPT model ratings are 'negative' | 450 | 0.04% | 0.0% |\n",
    "\n",
    "I hoped to process more data using GPT models, however, GPT 3.5 model was very slow when I tried to do it, so I was limited to 450 negative messages after 2 full days of trying to label more data. I think this was a sufficient number of rows to start training my models.  This process can be continued, once the initial results are formulated, in order to improve overall model quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Generating more negative class labels using Chat GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import openai\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization and pandas display options\n",
    "plt.rcParams['figure.figsize'] = (6.0, 4.0)\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set the global font to be used for all text\n",
    "plt.rcParams['font.family'] = 'Gill Sans' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103512, 17)\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "df_all = pd.read_csv('../data/reddit_cleaned.csv')\n",
    "print(df_all.shape)\n",
    "# df = df.head(9)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Eliminating rows and columns that are not relevant to investing and stock trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FolderName\n",
      "wallstreetbets          626064\n",
      "gme                     244318\n",
      "stocks                   51856\n",
      "pennystocks              42927\n",
      "investing                38162\n",
      "stockmarket              30119\n",
      "options                  27965\n",
      "robinhoodpennystocks     18111\n",
      "robinhood                17435\n",
      "finance                   6549\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting frequency counts for 'FolderName'\n",
    "folder_name_counts = df_all['FolderName'].value_counts()\n",
    "\n",
    "# Displaying the frequency counts\n",
    "print(folder_name_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103512, 17)\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where 'link_flair_text' is irrelevant\n",
    "\n",
    "# List of irrelevant flair texts\n",
    "irrelevant_flairs = ['Credit', 'Taxes', 'Other', 'Housing', 'Retirement', 'Planning', 'Saving', 'Debt', 'Auto', 'Employment', 'Insurance', \"Budgeting\", \"Advice\", 'Advice Request']\n",
    "\n",
    "# Filter out rows where 'link_flair_text' is in the list of irrelevant flairs\n",
    "df_all = df_all[~df_all['link_flair_text'].isin(irrelevant_flairs)].copy()\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102524, 17)\n"
     ]
    }
   ],
   "source": [
    "# Convert 'title' column to string\n",
    "df_all['Text'] = df_all['Text'].astype(str)\n",
    "\n",
    "# Filter out rows where 'title' starts with 'Daily '\n",
    "df_all = df_all[~df_all['Text'].str.startswith('Daily ')].copy()\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Optional filters (untoggle as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102524, 17)\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where 'selftext' is '[removed]'\n",
    "#df_all = df_all[df_all['selftext'] != '[removed]'].copy()\n",
    "#df_all = df_all[df_all['selftext'] != '[deleted]'].copy()\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime\n",
    "df_all['date'] = pd.to_datetime(df_all['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(437428, 17)\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'date' is before April 1, 2021\n",
    "df = df_all[df_all['date'] > '2021-04-01'].copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows containing \"GME\", \"Gamestop\", or \"$GME\" in the 'Text' column\n",
    "df_all = df_all[df_all['Text'].str.contains(r'GME|Gamestop|\\$GME', case=False, regex=True)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Only keeping the text fields in a smaller dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the 'id', 'title', and 'selftext' columns\n",
    "df = df_all[['id', 'Text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 154817 entries, 0 to 1103503\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      154817 non-null  object\n",
      " 1   Text    154817 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144491</th>\n",
       "      <td>l68e3t</td>\n",
       "      <td>TDA is rejecting all buys I'm placing for $BB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116952</th>\n",
       "      <td>m0rt9b</td>\n",
       "      <td>VW mega squeeze vs GME ultra mega MOASS Please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091456</th>\n",
       "      <td>l7b25y</td>\n",
       "      <td>Put 10k in GME today [removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717711</th>\n",
       "      <td>mg4lrd</td>\n",
       "      <td>GME CoNt. Fam 1st, Tendiez Later. nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492538</th>\n",
       "      <td>lb4zew</td>\n",
       "      <td>Do you guys think Revolut will release trading...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               Text\n",
       "144491   l68e3t  TDA is rejecting all buys I'm placing for $BB ...\n",
       "116952   m0rt9b  VW mega squeeze vs GME ultra mega MOASS Please...\n",
       "1091456  l7b25y                     Put 10k in GME today [removed]\n",
       "717711   mg4lrd              GME CoNt. Fam 1st, Tendiez Later. nan\n",
       "492538   lb4zew  Do you guys think Revolut will release trading..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               Text\n",
      "43   msblc3   GME YOLO update — Apr 16 2021 — final update nan\n",
      "59   pu7l07  What Are Your Moves Tomorrow, September 24, 20...\n",
      "74   mqp6lv  COIN IPO Megathread 4/14/2021 This is a megath...\n",
      "122  pk8tne  For anyone who doesn’t understand why Hedgefon...\n",
      "123  nuxr2t  r/GME Megathread for Tuesday - June 08, 2021 T...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df[['id', 'Text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Eliminating lengthy messages (too expensive for chat GPT processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Function to estimate tokens\n",
    "def estimate_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Applying the function to your dataframe\n",
    "df['token_count'] = df['Text'].apply(estimate_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229945</th>\n",
       "      <td>qh0frd</td>\n",
       "      <td>(Theory) For 10/26 Accounts, Shares, ComputerS...</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>lyuv1n</td>\n",
       "      <td>Can't stop thinking about that one guy who sai...</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010278</th>\n",
       "      <td>lcs8at</td>\n",
       "      <td>Probably TLWR, but here’s my opinion... “Don’t...</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24194</th>\n",
       "      <td>ldplrp</td>\n",
       "      <td>IS EVERYONE HERE LITERALLY A RETARD?? HOW CAN ...</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214080</th>\n",
       "      <td>r661hi</td>\n",
       "      <td>Smooth brained ape need help… advice on transf...</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               Text  \\\n",
       "229945   qh0frd  (Theory) For 10/26 Accounts, Shares, ComputerS...   \n",
       "1171     lyuv1n  Can't stop thinking about that one guy who sai...   \n",
       "1010278  lcs8at  Probably TLWR, but here’s my opinion... “Don’t...   \n",
       "24194    ldplrp  IS EVERYONE HERE LITERALLY A RETARD?? HOW CAN ...   \n",
       "214080   r661hi  Smooth brained ape need help… advice on transf...   \n",
       "\n",
       "         token_count  \n",
       "229945          1291  \n",
       "1171             511  \n",
       "1010278          613  \n",
       "24194           1850  \n",
       "214080           485  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_rows = df[df['token_count'] > 400]\n",
    "long_rows.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>697314</th>\n",
       "      <td>lxw5ts</td>\n",
       "      <td>Is it too late to get into GME? [removed]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017446</th>\n",
       "      <td>l74h6d</td>\n",
       "      <td>Vanguard allowing GME trading again [removed]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436010</th>\n",
       "      <td>n500mb</td>\n",
       "      <td>Finally unbanned and i can post this. GME [del...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42241</th>\n",
       "      <td>le0rp4</td>\n",
       "      <td>We gotta calm down, recoup, and replan for GME...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100990</th>\n",
       "      <td>m9lp1r</td>\n",
       "      <td>Lyfe of a GME Hodler nan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               Text  \\\n",
       "697314   lxw5ts          Is it too late to get into GME? [removed]   \n",
       "1017446  l74h6d      Vanguard allowing GME trading again [removed]   \n",
       "436010   n500mb  Finally unbanned and i can post this. GME [del...   \n",
       "42241    le0rp4  We gotta calm down, recoup, and replan for GME...   \n",
       "100990   m9lp1r                           Lyfe of a GME Hodler nan   \n",
       "\n",
       "         token_count  \n",
       "697314            14  \n",
       "1017446           11  \n",
       "436010            15  \n",
       "42241             18  \n",
       "100990             9  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_rows = df[df['token_count'] < 20]\n",
    "short_rows.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144049, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows where token_count is greater than 400\n",
    "df = df[df['token_count'] <= 400].reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87295, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows where token_count is smaller than 20\n",
    "df = df[df['token_count'] > 20].reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6959976\n"
     ]
    }
   ],
   "source": [
    "token_total = df['token_count'].agg(\"sum\")\n",
    "print(token_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.0\n"
     ]
    }
   ],
   "source": [
    "token_average = df['token_count'].agg(\"median\")\n",
    "print(token_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87295 entries, 0 to 87294\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           87295 non-null  object\n",
      " 1   Text         87295 non-null  object\n",
      " 2   token_count  87295 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df.index[0:87292], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Messages fed to GPT 3.5 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was written with the help of Chat GPT, as I wasn’t able to navigate all the complexities of the OpenAi API on my own.  In particular, I struggled with the throttling of API requests, and I could not figure out how to slow down the requests (number of API requests per minute), so Chat GPT was used to add the throttling function and the batch processing function.  \n",
    "\n",
    "The code was designed to analyse sentiment in Reddit messages selected above. \n",
    "\n",
    "1) The ask_gpt function sends text to the GPT-3.5 model and returns its response, handling exceptions if they occur. \n",
    "2) The throttled_request function includes a delay between requests. \n",
    "3) The main function, process_batch, processes data in small batches (only several rows at a time, in case the system becomes non-responsive). The function sends a prompt to GPT model and the response is a sentiment tag 'Positive', 'Negative', or 'Unclear'.  \n",
    "4) The results are then saved to a CSV file in batches, with the ability to append results. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 of 0\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Function to send text to GPT-3.5 and receive sentiment tag\n",
    "openai.api_key = \"OPENAI_API_KEY\"\n",
    "\n",
    "def ask_gpt(text):\n",
    "    try:\n",
    "        # Sending the prompt to the ChatGPT model and getting the response\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\", \n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "                      {\"role\": \"user\", \"content\": text}]\n",
    "        )\n",
    "        # Returning the text of the response\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "def throttled_request(text, delay=1.0):\n",
    "    response = ask_gpt(text)\n",
    "    time.sleep(delay)\n",
    "    return response\n",
    "\n",
    "# Function to process a batch and append results to a CSV file\n",
    "def process_batch(df, batch_size, csv_file):\n",
    "    start = 0\n",
    "    while start < len(df):\n",
    "        end = min(start + batch_size, len(df))\n",
    "        batch = df.iloc[start:end].copy()\n",
    "        batch['Sentiment_Tag'] = batch['Text'].apply(lambda text: throttled_request(f\"\"\"\n",
    "You will be presented with a Reddit message and your job is to provide in return a sentiment tag: \n",
    "choose either the “Positive” OR “Negative” OR “Unclear” tag but NOT several. \n",
    "Assess the sentiment of a Reddit message concerning shares, identified by company names or stock tickers. \n",
    "Focus exclusively on sentiments about the shares' performance, not the overall business performance. \n",
    "Evaluate the entire post. \n",
    "Classify the sentiment as 'Positive' for actions like buying calls, holding call options, or selling put options; \n",
    "'Negative' for buying puts, holding put options, or selling call options; \n",
    "and 'Unclear' for neutral, mixed, conflicting sentiments, or unclear mentions. \n",
    "Return back a tag with a sentiment concerning the shares. Choose tags ONLY from the list of tags provided above. \n",
    "Provide in response just a tag without an explanation.\n",
    "Message: {text}\"\"\"))\n",
    "        # Append batch results to CSV file\n",
    "        if start == 0:\n",
    "            batch.to_csv(csv_file, mode='w', header=True, index=False)  \n",
    "        else:\n",
    "            batch.to_csv(csv_file, mode='a', header=False, index=False)  \n",
    "        \n",
    "        start += batch_size\n",
    "        print(f\"Processed batch {start // batch_size} of {len(df) // batch_size}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 3  \n",
    "csv_file = '../data/wsb_sentiment_results.csv'\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "process_batch(df, batch_size, csv_file)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. GPT-4 repeat labelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12229, 4)\n"
     ]
    }
   ],
   "source": [
    "# Read in data saved in a csv file in the previoius step\n",
    "file_path = '../data/wsb_sentiment_results_Dec.csv'\n",
    "df_check = pd.read_csv(file_path)\n",
    "\n",
    "print(df_check.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a resut of partial processing of the Reddit unlabelled messages with Chat GPT 3.5 API I have accumulated 12229 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>Sentiment_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mn9wok</td>\n",
       "      <td>Cash account only guys any margin account they can lend your shares to shorties. Raising awareness. Hey apes. If you have E*TRADE Robinhood fidelity make sure you make your account a cash account so they don’t lend out your shares. On we bull if you hit the more options you can end the lending. I just looked and they lended my GameStop to dirty short sellers and gave me less than a penny in interest. Turn of stock lending on Webull. Call your brokerage apes. Apes strong together. We must have only cash account so that shorts can’t have our shares. 🦍🦍🦍🦍🦍🦍</td>\n",
       "      <td>145</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mndjhu</td>\n",
       "      <td>Good morning GME Fur Fam !! -boots 😺🦍✊🏼💎 nan</td>\n",
       "      <td>24</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0  mn9wok   \n",
       "1  mndjhu   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Text  \\\n",
       "0  Cash account only guys any margin account they can lend your shares to shorties. Raising awareness. Hey apes. If you have E*TRADE Robinhood fidelity make sure you make your account a cash account so they don’t lend out your shares. On we bull if you hit the more options you can end the lending. I just looked and they lended my GameStop to dirty short sellers and gave me less than a penny in interest. Turn of stock lending on Webull. Call your brokerage apes. Apes strong together. We must have only cash account so that shorts can’t have our shares. 🦍🦍🦍🦍🦍🦍   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Good morning GME Fur Fam !! -boots 😺🦍✊🏼💎 nan   \n",
       "\n",
       "   token_count Sentiment_Tag  \n",
       "0          145      Negative  \n",
       "1           24      Positive  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set maximum column width to None to display full text content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_check.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment_Tag\n",
      "Unclear     5838\n",
      "Positive    4908\n",
      "Negative    1332\n",
      "Error        136\n",
      "Neutral       10\n",
      "Unclear.       4\n",
      "Mixed          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting frequency counts for 'Sentiment_Tag'\n",
    "tag_counts = df_check['Sentiment_Tag'].value_counts()\n",
    "\n",
    "# Displaying the frequency counts\n",
    "print(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1337, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping all the rows with non-negative sentiment tags\n",
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Error'].copy()\n",
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Unclear'].copy()\n",
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Positive'].copy()\n",
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Neutral'].copy()\n",
    "df_check.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, I have 1337 negative ratings, or 10.9% of the data given to GPT 3.5 (first \"set of eyes\"). This percentage seems to be reasonable and consistent with my expectations. \n",
    "\n",
    "When I review the quality of the GPT 3.5 ratings, I notice that while many of them are correct, not all of them are perfectly on point.  Some ratings I disagree with. In order to increase my confidence in having good quality ratings, I decided to screen them again, using a different GPT model (GPT 4). \n",
    "\n",
    "In the code below I am re-checking the negative ratings from the previous step with GPT-4, a more advanced model (also more expensive to process tokens). I essentially treat GPT-4 model as a second set of eyes (as another human) to confirm the ratings given to me by Chat GPT 3.5 model.  I record the results of GPT-4 model processing in a new column Sentiment_Tag_2, in batches, in a new csv file. \n",
    "\n",
    "For my negative ratings up sampling I will select only those that were rated as \"negative\" by both models. \n",
    "\n",
    "The code below is a replica of the code used in teh previous section, but with GPT-4 model, not GPT 3.5 as before: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 of 445\n",
      "Processed batch 2 of 445\n",
      "Processed batch 3 of 445\n",
      "Processed batch 4 of 445\n",
      "Processed batch 5 of 445\n",
      "Processed batch 6 of 445\n",
      "Processed batch 7 of 445\n",
      "Processed batch 8 of 445\n",
      "Processed batch 9 of 445\n",
      "Processed batch 10 of 445\n",
      "Processed batch 11 of 445\n",
      "Processed batch 12 of 445\n",
      "Processed batch 13 of 445\n",
      "Processed batch 14 of 445\n",
      "Processed batch 15 of 445\n",
      "Processed batch 16 of 445\n",
      "Processed batch 17 of 445\n",
      "Processed batch 18 of 445\n",
      "Processed batch 19 of 445\n",
      "Processed batch 20 of 445\n",
      "Processed batch 21 of 445\n",
      "Processed batch 22 of 445\n",
      "Processed batch 23 of 445\n",
      "Processed batch 24 of 445\n",
      "Processed batch 25 of 445\n",
      "Processed batch 26 of 445\n",
      "Processed batch 27 of 445\n",
      "Processed batch 28 of 445\n",
      "Processed batch 29 of 445\n",
      "Processed batch 30 of 445\n",
      "Processed batch 31 of 445\n",
      "Processed batch 32 of 445\n",
      "Processed batch 33 of 445\n",
      "Processed batch 34 of 445\n",
      "Processed batch 35 of 445\n",
      "Processed batch 36 of 445\n",
      "Processed batch 37 of 445\n",
      "Processed batch 38 of 445\n",
      "Processed batch 39 of 445\n",
      "Processed batch 40 of 445\n",
      "Processed batch 41 of 445\n",
      "Processed batch 42 of 445\n",
      "Processed batch 43 of 445\n",
      "Processed batch 44 of 445\n",
      "Processed batch 45 of 445\n",
      "Processed batch 46 of 445\n",
      "Processed batch 47 of 445\n",
      "Processed batch 48 of 445\n",
      "Processed batch 49 of 445\n",
      "Processed batch 50 of 445\n",
      "Processed batch 51 of 445\n",
      "Processed batch 52 of 445\n",
      "Processed batch 53 of 445\n",
      "Processed batch 54 of 445\n",
      "Processed batch 55 of 445\n",
      "Processed batch 56 of 445\n",
      "Processed batch 57 of 445\n",
      "Processed batch 58 of 445\n",
      "Processed batch 59 of 445\n",
      "Processed batch 60 of 445\n",
      "Processed batch 61 of 445\n",
      "Processed batch 62 of 445\n",
      "Processed batch 63 of 445\n",
      "Processed batch 64 of 445\n",
      "Processed batch 65 of 445\n",
      "Processed batch 66 of 445\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/wsb_sentiment_results_check.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Process the DataFrame in batches\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 29\u001b[0m, in \u001b[0;36mprocess_batch\u001b[0;34m(df, batch_size, csv_file)\u001b[0m\n\u001b[1;32m     27\u001b[0m         end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m batch_size, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[1;32m     28\u001b[0m         batch \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start:end]\u001b[38;5;241m.\u001b[39mcopy()  \n\u001b[0;32m---> 29\u001b[0m         batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment_Tag_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrottled_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mYou will be presented with a Reddit message and your job is to provide in return a sentiment tag: choose either the “Positive” OR “Negative” OR “Unclear” tag but NOT several). \u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43mAssess the sentiment of a Reddit message concerning shares, identified by company names or stock tickers. \u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43mFocus exclusively on sentiments about the shares\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m performance, not the overall business performance. Evaluate the entire post. \u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43mClassify the sentiment as \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m for actions like buying shares, buying call options, holding call options, or selling put options; \u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNegative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m for selling shares, or buying puts, or holding put options, or selling call options; \u001b[39;49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;43mand \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnclear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m for neutral, mixed, conflicting sentiments, or unclear mentions. \u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43mReturn back a tag with a sentiment concerning the shares. Choose tags ONLY from the list of tags provided above. \u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43mProvide in response just a tag without an explanation.\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43mMessage: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# Append batch results to CSV file\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv2/lib/python3.8/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv2/lib/python3.8/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv2/lib/python3.8/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv2/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[40], line 29\u001b[0m, in \u001b[0;36mprocess_batch.<locals>.<lambda>\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     27\u001b[0m         end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m batch_size, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[1;32m     28\u001b[0m         batch \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start:end]\u001b[38;5;241m.\u001b[39mcopy()  \n\u001b[0;32m---> 29\u001b[0m         batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment_Tag_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m text: \u001b[43mthrottled_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mYou will be presented with a Reddit message and your job is to provide in return a sentiment tag: choose either the “Positive” OR “Negative” OR “Unclear” tag but NOT several). \u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43mAssess the sentiment of a Reddit message concerning shares, identified by company names or stock tickers. \u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43mFocus exclusively on sentiments about the shares\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m performance, not the overall business performance. Evaluate the entire post. \u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43mClassify the sentiment as \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m for actions like buying shares, buying call options, holding call options, or selling put options; \u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNegative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m for selling shares, or buying puts, or holding put options, or selling call options; \u001b[39;49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;43mand \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnclear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m for neutral, mixed, conflicting sentiments, or unclear mentions. \u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43mReturn back a tag with a sentiment concerning the shares. Choose tags ONLY from the list of tags provided above. \u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43mProvide in response just a tag without an explanation.\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43mMessage: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# Append batch results to CSV file\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[40], line 20\u001b[0m, in \u001b[0;36mthrottled_request\u001b[0;34m(text, delay)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mthrottled_request\u001b[39m(text, delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m):\n\u001b[1;32m     19\u001b[0m     response \u001b[38;5;241m=\u001b[39m ask_gpt(text)\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to send text to GPT-4 and receive sentiment tag (you need to implement this)\n",
    "openai.api_key = \"ZZZZZZ\" # place your own API key here\n",
    "\n",
    "def ask_gpt(text):\n",
    "    try:\n",
    "        # Sending the prompt to the ChatGPT model and getting the response\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",  \n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "                      {\"role\": \"user\", \"content\": text}]\n",
    "        )\n",
    "        # Returning the text of the response\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "def throttled_request(text, delay=5.0):\n",
    "    response = ask_gpt(text)\n",
    "    time.sleep(delay)\n",
    "    return response\n",
    "\n",
    "# Function to process a batch and append results to a CSV file\n",
    "def process_batch(df, batch_size, csv_file):\n",
    "    start = 0\n",
    "    while start < len(df):\n",
    "        end = min(start + batch_size, len(df))\n",
    "        batch = df.iloc[start:end].copy()  \n",
    "        batch['Sentiment_Tag_2'] = batch['Text'].apply(lambda text: throttled_request(f\"\"\"You will be presented with a Reddit message and your job is to provide in return a sentiment tag: choose either the “Positive” OR “Negative” OR “Unclear” tag but NOT several). \n",
    "Assess the sentiment of a Reddit message concerning shares, identified by company names or stock tickers. \n",
    "Focus exclusively on sentiments about the shares' performance, not the overall business performance. Evaluate the entire post. \n",
    "Classify the sentiment as 'Positive' for actions like buying shares, buying call options, holding call options, or selling put options; \n",
    "'Negative' for selling shares, or buying puts, or holding put options, or selling call options; \n",
    "and 'Unclear' for neutral, mixed, conflicting sentiments, or unclear mentions. \n",
    "Return back a tag with a sentiment concerning the shares. Choose tags ONLY from the list of tags provided above. \n",
    "Provide in response just a tag without an explanation.\n",
    "Message: {text}\"\"\"))\n",
    "        # Append batch results to CSV file\n",
    "        if start == 0:\n",
    "            batch.to_csv(csv_file, mode='w', header=True, index=False)  \n",
    "        else:\n",
    "            batch.to_csv(csv_file, mode='a', header=False, index=False)  \n",
    "        \n",
    "        start += batch_size\n",
    "        print(f\"Processed batch {start // batch_size} of {len(df) // batch_size}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 3  \n",
    "csv_file = '../data/wsb_sentiment_results_check.csv'\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "process_batch(df_check, batch_size, csv_file)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Re-checking the chat GPT-4 ratings and comparing two GPT model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_check_gpt4 = pd.read_csv('../data/wsb_sentiment_results_check.csv')\n",
    "print(df_check_gpt4.shape)\n",
    "# df = df.head(9)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_gpt4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at the new ratings (see new column Sentriment_Tag_2),  anc comparing the output of two GPT models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_gpt4.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting frequency counts for 'Sentiment_Tag'\n",
    "tag_counts = df_check_gpt4['Sentiment_Tag_2'].value_counts()\n",
    "\n",
    "# Displaying the frequency counts\n",
    "print(tag_counts)\n",
    "df_check_gpt4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a considerable degree of disagreement between the two GPT models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crosstab of the two columns\n",
    "crosstab_result = pd.crosstab(df_check_gpt4['Sentiment_Tag'], df_check_gpt4['Sentiment_Tag_2'])\n",
    "\n",
    "# Plotting the crosstab\n",
    "plt.figure(figsize=(4, 2))  \n",
    "sns.heatmap(crosstab_result, annot=True, fmt=\"d\", cmap=\"coolwarm\")  # 'fmt' is format of the annotation (integer in this case)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Crosstab of GPT 4 vs GPT 3.5')\n",
    "plt.xlabel('Sentiment GPT 4')\n",
    "plt.ylabel('Sentiment GPT 3.5')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "450 rows weer rated as \"negative\" by both GPT models.  This is 62% of the starting number of rows rated as negative by Chat GPT 3.5 (725 rows).  In 9% of cases Chat GPT 4 completely disagreed with the negative rating given by Chat GPT 3.5 and assigned \"positive\" rating to the text. \n",
    "\n",
    "**Conclusion**:  I will treat those instances where both Chat GPT models agreed that the rating was \"negative\" as the additional \"ground truth\" for my model training.  This will help to address the deficit of negative ratings in the labelled dataset and will help in training my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows where two GPT models disagree with each other. Keeping only those rows where both ratings are \"negative\"\n",
    "df_check_gpt4 = df_check_gpt4[df_check_gpt4['Sentiment_Tag_2'] != 'Unclear'].copy()\n",
    "df_check_gpt4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_check_gpt4 = df_check_gpt4[df_check_gpt4['Sentiment_Tag_2'] != 'Positive'].copy()\n",
    "df_check_gpt4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_check_gpt4.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Cleaning the newly generated negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below I repeat the same cleaning steps as in the notbook 01 Labelled EDA and Cleaning, to ensure pre-processing consistency: \n",
    "\n",
    "* checking for missing values and duplicates\n",
    "* removing website inks (urls), hashtags (#) and mentions (@)\n",
    "* the resulting dataset is then saved into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_gpt4[ df_check_gpt4['Text'].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_gpt4[df_check_gpt4['Text'].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_check_gpt4.copy()\n",
    "df_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def purge_content(text):\n",
    "    text_without_urls = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text_without_hashtags = re.sub(r'#\\S+', '', text_without_urls)\n",
    "    text_without_mentions = re.sub(r'@\\S+', '', text_without_hashtags)\n",
    "    text_without_linebreaks = re.sub(r'\\n+', '', text_without_mentions)\n",
    "    clean_text = re.sub(r'\\n+', ' ', text_without_linebreaks)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using apply() method to clean the text\n",
    "df_clean['Text'] = df_clean['Text'].apply(purge_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9. Saving the cleaned dataframe into a CSV file for further steps in modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df_clean.to_csv('../data/reddit_gpt4_negative_only_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I have identified 450 additional negative intentions messages.  \n",
    "* 3.6 thousands messages fed to two GPT models yielded 450 double labelled negative messages. \n",
    "* Total cost - around $12.  \n",
    "* The main limiting factor was time, as GPT 3.5 API is very slow and prone to freezing up and crashing.  \n",
    "\n",
    "I will use the newly labelled messages to upsample my imbalaned labelled dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
