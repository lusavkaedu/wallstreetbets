{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating more negative class labels using Chat GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import openai\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260374, 18)\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "df_all = pd.read_csv('../data/reddit_cleaned_slim.csv')\n",
    "print(df_all.shape)\n",
    "# df = df.head(9)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating rows and columns that are not relevant to investing and stock trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FolderName\n",
      "wallstreetbets          719899\n",
      "gme                     268376\n",
      "stocks                   68524\n",
      "pennystocks              50712\n",
      "stockmarket              41388\n",
      "investing                38162\n",
      "options                  27965\n",
      "robinhoodpennystocks     21235\n",
      "robinhood                17564\n",
      "finance                   6549\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting frequency counts for 'FolderName'\n",
    "folder_name_counts = df_all['FolderName'].value_counts()\n",
    "\n",
    "# Displaying the frequency counts\n",
    "print(folder_name_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1246161, 18)\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where 'link_flair_text' is irrelevant\n",
    "\n",
    "# List of irrelevant flair texts\n",
    "irrelevant_flairs = ['Credit', 'Taxes', 'Other', 'Housing', 'Retirement', 'Planning', 'Saving', 'Debt', 'Auto', 'Employment', 'Insurance', \"Budgeting\", \"Advice\", 'Advice Request']\n",
    "\n",
    "# Filter out rows where 'link_flair_text' is in the list of irrelevant flairs\n",
    "df_all = df_all[~df_all['link_flair_text'].isin(irrelevant_flairs)].copy()\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1245087, 18)\n"
     ]
    }
   ],
   "source": [
    "# Convert 'title' column to string\n",
    "df_all['title'] = df_all['title'].astype(str)\n",
    "\n",
    "# Filter out rows where 'title' starts with 'Daily '\n",
    "df_all = df_all[~df_all['title'].str.startswith('Daily ')].copy()\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional filters (untoggle as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618703, 18)\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where 'selftext' is '[removed]'\n",
    "df_all = df_all[df_all['selftext'] != '[removed]'].copy()\n",
    "df_all = df_all[df_all['selftext'] != '[deleted]'].copy()\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime\n",
    "df_all['date'] = pd.to_datetime(df_all['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489325, 18)\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'date' is before April 1, 2021\n",
    "df_all = df_all[df_all['date'] > '2021-04-01'].copy()\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows containing \"GME\", \"Gamestop\", or \"$GME\" in the 'Text' column\n",
    "#df = df[df['Text'].str.contains(r'GME|Gamestop|\\$GME', case=False, regex=True)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only keeping the text fields in a smaller dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the 'id', 'title', and 'selftext' columns\n",
    "df = df_all[['id', 'title', 'selftext']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 489325 entries, 46 to 1048980\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        489325 non-null  object\n",
      " 1   title     489325 non-null  object\n",
      " 2   selftext  296880 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 14.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473088</th>\n",
       "      <td>rcykn5</td>\n",
       "      <td>Why invest in Liberty Oilfield Services?</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401438</th>\n",
       "      <td>qfmagt</td>\n",
       "      <td>Blackberry shares thoughts?</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792572</th>\n",
       "      <td>nuhd4n</td>\n",
       "      <td>To the moon!!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197229</th>\n",
       "      <td>mx0jcm</td>\n",
       "      <td>It’s going to happen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990785</th>\n",
       "      <td>mkbmic</td>\n",
       "      <td>Easter &amp; Egg Hunting with the Fam was fun.. Ok...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title   selftext\n",
       "473088  rcykn5           Why invest in Liberty Oilfield Services?  [removed]\n",
       "401438  qfmagt                        Blackberry shares thoughts?  [removed]\n",
       "792572  nuhd4n                                      To the moon!!        NaN\n",
       "197229  mx0jcm                               It’s going to happen        NaN\n",
       "990785  mkbmic  Easter & Egg Hunting with the Fam was fun.. Ok...        NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               Text\n",
      "46   msblc3  GME YOLO update — Apr 16 2021 — final update, nan\n",
      "69   pu7l07  What Are Your Moves Tomorrow, September 24, 20...\n",
      "87   mqp6lv  COIN IPO Megathread 4/14/2021, This is a megat...\n",
      "155  pk8tne  For anyone who doesn’t understand why Hedgefon...\n",
      "158  nuxr2t  r/GME Megathread for Tuesday - June 08, 2021, ...\n"
     ]
    }
   ],
   "source": [
    "# Concatenating 'title' and 'selftext' with a comma separator\n",
    "df['Text'] = df.apply(lambda row: f\"{row['title']}, {row['selftext']}\", axis=1)\n",
    "\n",
    "# Displaying the first few rows of the new concatenated column\n",
    "print(df[['id', 'Text']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating lengthy messages (too expensive and lengthy for chat GPT processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Function to estimate tokens\n",
    "def estimate_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Applying the function to your dataframe\n",
    "df['token_count'] = df['Text'].apply(estimate_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>Text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23441</th>\n",
       "      <td>nlhcci</td>\n",
       "      <td>Accounting 101 - Part 1: The Income Statement</td>\n",
       "      <td>Hey everyone, here's the first part to a serie...</td>\n",
       "      <td>Accounting 101 - Part 1: The Income Statement,...</td>\n",
       "      <td>3035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378880</th>\n",
       "      <td>mr9gvc</td>\n",
       "      <td>4/16 Option Scraper Data: Total Calls, ITM Cal...</td>\n",
       "      <td>Total Calls:\\n\\n&amp;#x200B;\\n\\nhttps://preview.re...</td>\n",
       "      <td>4/16 Option Scraper Data: Total Calls, ITM Cal...</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144692</th>\n",
       "      <td>os3ca6</td>\n",
       "      <td>Newbie trade -- what do you think?</td>\n",
       "      <td>I own about 350 shares of $WFC. Because of all...</td>\n",
       "      <td>Newbie trade -- what do you think?, I own abou...</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037366</th>\n",
       "      <td>mw7gvc</td>\n",
       "      <td>$ZKIN. Another one to the moon?</td>\n",
       "      <td>Since the last 15m outlook the price of ZKIN g...</td>\n",
       "      <td>$ZKIN. Another one to the moon?, Since the las...</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163123</th>\n",
       "      <td>nv2atm</td>\n",
       "      <td>What's the best way to simulate leveraged buy ...</td>\n",
       "      <td>Hi all, I've learned a lot from this sub so th...</td>\n",
       "      <td>What's the best way to simulate leveraged buy ...</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title  \\\n",
       "23441    nlhcci      Accounting 101 - Part 1: The Income Statement   \n",
       "378880   mr9gvc  4/16 Option Scraper Data: Total Calls, ITM Cal...   \n",
       "144692   os3ca6                 Newbie trade -- what do you think?   \n",
       "1037366  mw7gvc                    $ZKIN. Another one to the moon?   \n",
       "163123   nv2atm  What's the best way to simulate leveraged buy ...   \n",
       "\n",
       "                                                  selftext  \\\n",
       "23441    Hey everyone, here's the first part to a serie...   \n",
       "378880   Total Calls:\\n\\n&#x200B;\\n\\nhttps://preview.re...   \n",
       "144692   I own about 350 shares of $WFC. Because of all...   \n",
       "1037366  Since the last 15m outlook the price of ZKIN g...   \n",
       "163123   Hi all, I've learned a lot from this sub so th...   \n",
       "\n",
       "                                                      Text  token_count  \n",
       "23441    Accounting 101 - Part 1: The Income Statement,...         3035  \n",
       "378880   4/16 Option Scraper Data: Total Calls, ITM Cal...          334  \n",
       "144692   Newbie trade -- what do you think?, I own abou...          350  \n",
       "1037366  $ZKIN. Another one to the moon?, Since the las...          360  \n",
       "163123   What's the best way to simulate leveraged buy ...          461  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_rows = df[df['token_count'] > 300]\n",
    "long_rows.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>Text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93073</th>\n",
       "      <td>o5bjl4</td>\n",
       "      <td>Dave Lauer Speaking The Truth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dave Lauer Speaking The Truth, nan</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367092</th>\n",
       "      <td>pjfr63</td>\n",
       "      <td>I want everyone’s honest opinions on CLOV</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>I want everyone’s honest opinions on CLOV, [re...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720139</th>\n",
       "      <td>opqoz8</td>\n",
       "      <td>Thinking</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Thinking, [removed]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>ppb0hn</td>\n",
       "      <td>Probably should have asked in the daily, but i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Probably should have asked in the daily, but i...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350772</th>\n",
       "      <td>nrha48</td>\n",
       "      <td>In 2021, WSB had some fun 🚀</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In 2021, WSB had some fun 🚀, nan</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title   selftext  \\\n",
       "93073   o5bjl4                      Dave Lauer Speaking The Truth        NaN   \n",
       "367092  pjfr63          I want everyone’s honest opinions on CLOV  [removed]   \n",
       "720139  opqoz8                                           Thinking  [removed]   \n",
       "7706    ppb0hn  Probably should have asked in the daily, but i...        NaN   \n",
       "350772  nrha48                        In 2021, WSB had some fun 🚀        NaN   \n",
       "\n",
       "                                                     Text  token_count  \n",
       "93073                  Dave Lauer Speaking The Truth, nan            8  \n",
       "367092  I want everyone’s honest opinions on CLOV, [re...           16  \n",
       "720139                                Thinking, [removed]            7  \n",
       "7706    Probably should have asked in the daily, but i...           18  \n",
       "350772                   In 2021, WSB had some fun 🚀, nan           13  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_rows = df[df['token_count'] < 20]\n",
    "short_rows.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241354, 5)\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows where token_count is greater than 400\n",
    "df = df[df['token_count'] <= 400].reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111183, 5)\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows where token_count is smaller than 20\n",
    "df = df[df['token_count'] > 20].reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9751341\n"
     ]
    }
   ],
   "source": [
    "token_total = df['token_count'].agg(\"sum\")\n",
    "print(token_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.0\n"
     ]
    }
   ],
   "source": [
    "token_average = df['token_count'].agg(\"median\")\n",
    "print(token_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111183 entries, 0 to 111182\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   id           111183 non-null  object\n",
      " 1   title        111183 non-null  object\n",
      " 2   selftext     47707 non-null   object\n",
      " 3   Text         111183 non-null  object\n",
      " 4   token_count  111183 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df.index[0:3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111183, 5)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send text to GPT-4 and receive sentiment tag (you need to implement this)\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def ask_gpt(text):\n",
    "    try:\n",
    "        # Sending the prompt to the ChatGPT model and getting the response\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Adjust the model name as needed\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "                      {\"role\": \"user\", \"content\": text}]\n",
    "        )\n",
    "        # Returning the text of the response\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "def throttled_request(text, delay=1.0):\n",
    "    response = ask_gpt(text)\n",
    "    time.sleep(delay)\n",
    "    return response\n",
    "\n",
    "# Function to process a batch and append results to a CSV file\n",
    "def process_batch(df, batch_size, csv_file):\n",
    "    start = 0\n",
    "    while start < len(df):\n",
    "        end = min(start + batch_size, len(df))\n",
    "        batch = df.iloc[start:end].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "        batch['Sentiment_Tag'] = batch['Text'].apply(lambda text: throttled_request(f\"\"\"You will be presented with a Reddit message and your job is to provide in return a sentiment tag: choose either the “Positive” OR “Negative” OR “Unclear” tag but NOT several). \n",
    "Assess the sentiment of a Reddit message concerning shares, identified by company names or stock tickers. \n",
    "Focus exclusively on sentiments about the shares' performance, not the overall business performance. Evaluate the entire post. \n",
    "Classify the sentiment as 'Positive' for actions like buying calls, holding call options, or selling put options; \n",
    "'Negative' for buying puts, holding put options, or selling call options; \n",
    "and 'Unclear' for neutral, mixed, conflicting sentiments, or unclear mentions. \n",
    "Return back a tag with a sentiment concerning the shares. Choose tags ONLY from the list of tags provided above. \n",
    "Provide in response just a tag without an explanation.\n",
    "Message: {text}\"\"\"))\n",
    "        # Append batch results to CSV file\n",
    "        if start == 0:\n",
    "            batch.to_csv(csv_file, mode='w', header=True, index=False)  # Write mode with header for the first batch\n",
    "        else:\n",
    "            batch.to_csv(csv_file, mode='a', header=False, index=False)  # Append mode without header for subsequent batches\n",
    "        \n",
    "        start += batch_size\n",
    "        print(f\"Processed batch {start // batch_size} of {len(df) // batch_size}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 3  # Adjust this based on your needs\n",
    "csv_file = '../data/wsb_sentiment_results.csv'\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "process_batch(df, batch_size, csv_file)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-checking the chat GPT rating by sending a portion of the negative ratings again back to chat GPT, for a repeat rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1602, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "df_check = pd.read_csv('wsb_sentiment_results.csv')\n",
    "print(df_check.shape)\n",
    "# df = df.head(9)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a resut of partial processing of the Reddit unlabelled messages with Chat GPT 3.5 API I have accumulated 1602 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>Text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>Sentiment_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mqp6lv</td>\n",
       "      <td>COIN IPO Megathread 4/14/2021</td>\n",
       "      <td>This is a megathread for the $COIN IPO.  We will allow discussion of the COIN stock, but do note that the no crypto rule still applies.  If you use COIN as a proxy to discuss crypto, instead of discussing the stock, you will be banned.  It’s a bit of a gray line, so ensure that you keep discussion focused on the stock.\\n\\n\\nEdit: Direct Listing*</td>\n",
       "      <td>COIN IPO Megathread 4/14/2021, This is a megathread for the $COIN IPO.  We will allow discussion of the COIN stock, but do note that the no crypto rule still applies.  If you use COIN as a proxy to discuss crypto, instead of discussing the stock, you will be banned.  It’s a bit of a gray line, so ensure that you keep discussion focused on the stock.\\n\\n\\nEdit: Direct Listing*</td>\n",
       "      <td>103</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pk8tne</td>\n",
       "      <td>For anyone who doesn’t understand why Hedgefonds lost, this ape explained it well.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>For anyone who doesn’t understand why Hedgefonds lost, this ape explained it well., nan</td>\n",
       "      <td>21</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oxwuiw</td>\n",
       "      <td>It absolutely blows my mind that so many people and especially people on this sub are STILL using Robinhood despite what happened with the whole gamestop fiasco.</td>\n",
       "      <td>There's still so many people using Robinhood after all the GME crap. And what really blows my mind is that I see people here on this very sub using Robinhood everyday? It absolutely baffles the living shit out of me as to why you are still using something that screwed you over, especially knowing very well that it could happen again and screw you over AGAIN. I don't want to see anyone who gets screwed over by Robinhood yet again complaining about it. You asked for it buddy.\\n\\nI know you stock market types only care about profit but godamn what kind of abusive relationship is this. This is mainly why I switched to the other market and projects like Merrymen who aim to undo this shit. What kind of abusive relationship do you people have with Robinhood. They give you a slick UI and you forget about all the wrongs they did to you? bruh.</td>\n",
       "      <td>It absolutely blows my mind that so many people and especially people on this sub are STILL using Robinhood despite what happened with the whole gamestop fiasco., There's still so many people using Robinhood after all the GME crap. And what really blows my mind is that I see people here on this very sub using Robinhood everyday? It absolutely baffles the living shit out of me as to why you are still using something that screwed you over, especially knowing very well that it could happen again and screw you over AGAIN. I don't want to see anyone who gets screwed over by Robinhood yet again complaining about it. You asked for it buddy.\\n\\nI know you stock market types only care about profit but godamn what kind of abusive relationship is this. This is mainly why I switched to the other market and projects like Merrymen who aim to undo this shit. What kind of abusive relationship do you people have with Robinhood. They give you a slick UI and you forget about all the wrongs they did to you? bruh.</td>\n",
       "      <td>214</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mjy92g</td>\n",
       "      <td>i'm about to YOLO my $800k life savings on starbucks gift cards, what are the tax implications ??</td>\n",
       "      <td>hey wsb i'm going to invest my life savings in starbucks gift cards cause i think the dollar is going to go down, i plan to sell them in a couple years and make an absolute killing\\n\\nwhat are the tax implications of doing this??\\n\\nwhat kind of investment vehicle are starbucks gift cards anyway? my polyamorous girlfriend says that they're most similar to bearer bonds, which makes sense; does that tie their value to starbucks' capitalization?</td>\n",
       "      <td>i'm about to YOLO my $800k life savings on starbucks gift cards, what are the tax implications ??, hey wsb i'm going to invest my life savings in starbucks gift cards cause i think the dollar is going to go down, i plan to sell them in a couple years and make an absolute killing\\n\\nwhat are the tax implications of doing this??\\n\\nwhat kind of investment vehicle are starbucks gift cards anyway? my polyamorous girlfriend says that they're most similar to bearer bonds, which makes sense; does that tie their value to starbucks' capitalization?</td>\n",
       "      <td>123</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p72imy</td>\n",
       "      <td>Ruined My Financial Future… This is 99% of my savings and basically everything that me and many family own… Need Baba back up to 243 to break even…</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruined My Financial Future… This is 99% of my savings and basically everything that me and many family own… Need Baba back up to 243 to break even…, nan</td>\n",
       "      <td>36</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0  mqp6lv   \n",
       "1  pk8tne   \n",
       "2  oxwuiw   \n",
       "3  mjy92g   \n",
       "4  p72imy   \n",
       "\n",
       "                                                                                                                                                               title  \\\n",
       "0                                                                                                                                      COIN IPO Megathread 4/14/2021   \n",
       "1                                                                                 For anyone who doesn’t understand why Hedgefonds lost, this ape explained it well.   \n",
       "2  It absolutely blows my mind that so many people and especially people on this sub are STILL using Robinhood despite what happened with the whole gamestop fiasco.   \n",
       "3                                                                  i'm about to YOLO my $800k life savings on starbucks gift cards, what are the tax implications ??   \n",
       "4                Ruined My Financial Future… This is 99% of my savings and basically everything that me and many family own… Need Baba back up to 243 to break even…   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This is a megathread for the $COIN IPO.  We will allow discussion of the COIN stock, but do note that the no crypto rule still applies.  If you use COIN as a proxy to discuss crypto, instead of discussing the stock, you will be banned.  It’s a bit of a gray line, so ensure that you keep discussion focused on the stock.\\n\\n\\nEdit: Direct Listing*   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            NaN   \n",
       "2  There's still so many people using Robinhood after all the GME crap. And what really blows my mind is that I see people here on this very sub using Robinhood everyday? It absolutely baffles the living shit out of me as to why you are still using something that screwed you over, especially knowing very well that it could happen again and screw you over AGAIN. I don't want to see anyone who gets screwed over by Robinhood yet again complaining about it. You asked for it buddy.\\n\\nI know you stock market types only care about profit but godamn what kind of abusive relationship is this. This is mainly why I switched to the other market and projects like Merrymen who aim to undo this shit. What kind of abusive relationship do you people have with Robinhood. They give you a slick UI and you forget about all the wrongs they did to you? bruh.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                 hey wsb i'm going to invest my life savings in starbucks gift cards cause i think the dollar is going to go down, i plan to sell them in a couple years and make an absolute killing\\n\\nwhat are the tax implications of doing this??\\n\\nwhat kind of investment vehicle are starbucks gift cards anyway? my polyamorous girlfriend says that they're most similar to bearer bonds, which makes sense; does that tie their value to starbucks' capitalization?   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        COIN IPO Megathread 4/14/2021, This is a megathread for the $COIN IPO.  We will allow discussion of the COIN stock, but do note that the no crypto rule still applies.  If you use COIN as a proxy to discuss crypto, instead of discussing the stock, you will be banned.  It’s a bit of a gray line, so ensure that you keep discussion focused on the stock.\\n\\n\\nEdit: Direct Listing*   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           For anyone who doesn’t understand why Hedgefonds lost, this ape explained it well., nan   \n",
       "2  It absolutely blows my mind that so many people and especially people on this sub are STILL using Robinhood despite what happened with the whole gamestop fiasco., There's still so many people using Robinhood after all the GME crap. And what really blows my mind is that I see people here on this very sub using Robinhood everyday? It absolutely baffles the living shit out of me as to why you are still using something that screwed you over, especially knowing very well that it could happen again and screw you over AGAIN. I don't want to see anyone who gets screwed over by Robinhood yet again complaining about it. You asked for it buddy.\\n\\nI know you stock market types only care about profit but godamn what kind of abusive relationship is this. This is mainly why I switched to the other market and projects like Merrymen who aim to undo this shit. What kind of abusive relationship do you people have with Robinhood. They give you a slick UI and you forget about all the wrongs they did to you? bruh.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 i'm about to YOLO my $800k life savings on starbucks gift cards, what are the tax implications ??, hey wsb i'm going to invest my life savings in starbucks gift cards cause i think the dollar is going to go down, i plan to sell them in a couple years and make an absolute killing\\n\\nwhat are the tax implications of doing this??\\n\\nwhat kind of investment vehicle are starbucks gift cards anyway? my polyamorous girlfriend says that they're most similar to bearer bonds, which makes sense; does that tie their value to starbucks' capitalization?   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Ruined My Financial Future… This is 99% of my savings and basically everything that me and many family own… Need Baba back up to 243 to break even…, nan   \n",
       "\n",
       "   token_count Sentiment_Tag  \n",
       "0          103       Unclear  \n",
       "1           21       Unclear  \n",
       "2          214      Negative  \n",
       "3          123       Unclear  \n",
       "4           36      Negative  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set maximum column width to None to display full text content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment_Tag\n",
      "Unclear     565\n",
      "Positive    484\n",
      "Negative    464\n",
      "Error        87\n",
      "Neutral       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting frequency counts for 'Sentiment_Tag'\n",
    "tag_counts = df_check['Sentiment_Tag'].value_counts()\n",
    "\n",
    "# Displaying the frequency counts\n",
    "print(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 6)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Error'].copy()\n",
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Unclear'].copy()\n",
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Positive'].copy()\n",
    "df_check = df_check[df_check['Sentiment_Tag'] != 'Neutral'].copy()\n",
    "df_check.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 464 negative ratings, or 29% of the data given to Chat GPT. \n",
    "\n",
    "When I review the quality of the GPT 3.5 ratings, I notice that while many of them are correct, not all of them are reasonable.  Some ratings I disagree with. In order to increae my confidence in having good quality ratings, I decided to screen them again, using a different GPT model. \n",
    "\n",
    "In the code below I am re-checking the negative ratings from the previous setp with Chat GPT-4, a more advanced model (also more expensive to process tokens). I essentially treat Chat GPT-4 as a second set of eyes (another human) to confirm the ratings given to me by Chat GPT 3.5 model.  I record the results of GPT-4 model processing in a new column Sentiment_Tag_2, in batches, in a new csv file. \n",
    "\n",
    "For my negative ratings upsampling I will select only those that were rated as \"negative\" by both models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 of 99\n",
      "Processed batch 2 of 99\n",
      "Processed batch 3 of 99\n",
      "Processed batch 4 of 99\n",
      "Processed batch 5 of 99\n",
      "Processed batch 6 of 99\n",
      "Processed batch 7 of 99\n",
      "Processed batch 8 of 99\n",
      "Processed batch 9 of 99\n",
      "Processed batch 10 of 99\n",
      "Processed batch 11 of 99\n",
      "Processed batch 12 of 99\n",
      "Processed batch 13 of 99\n",
      "Processed batch 14 of 99\n",
      "Processed batch 15 of 99\n",
      "Processed batch 16 of 99\n",
      "Processed batch 17 of 99\n",
      "Processed batch 18 of 99\n",
      "Processed batch 19 of 99\n",
      "Processed batch 20 of 99\n",
      "Processed batch 21 of 99\n",
      "Processed batch 22 of 99\n",
      "Processed batch 23 of 99\n",
      "Processed batch 24 of 99\n",
      "Processed batch 25 of 99\n",
      "Processed batch 26 of 99\n",
      "Processed batch 27 of 99\n",
      "Processed batch 28 of 99\n",
      "Processed batch 29 of 99\n",
      "Processed batch 30 of 99\n",
      "Processed batch 31 of 99\n",
      "Processed batch 32 of 99\n",
      "Processed batch 33 of 99\n",
      "Processed batch 34 of 99\n",
      "Processed batch 35 of 99\n",
      "Processed batch 36 of 99\n",
      "Processed batch 37 of 99\n",
      "Processed batch 38 of 99\n",
      "Processed batch 39 of 99\n",
      "Processed batch 40 of 99\n",
      "Processed batch 41 of 99\n",
      "Processed batch 42 of 99\n",
      "Processed batch 43 of 99\n",
      "Processed batch 44 of 99\n",
      "Processed batch 45 of 99\n",
      "Processed batch 46 of 99\n",
      "Processed batch 47 of 99\n",
      "Processed batch 48 of 99\n",
      "Processed batch 49 of 99\n",
      "Processed batch 50 of 99\n",
      "Processed batch 51 of 99\n",
      "Processed batch 52 of 99\n",
      "Processed batch 53 of 99\n",
      "Processed batch 54 of 99\n",
      "Processed batch 55 of 99\n",
      "Processed batch 56 of 99\n",
      "Processed batch 57 of 99\n",
      "Processed batch 58 of 99\n",
      "Processed batch 59 of 99\n",
      "Processed batch 60 of 99\n",
      "Processed batch 61 of 99\n",
      "Processed batch 62 of 99\n",
      "Processed batch 63 of 99\n",
      "Processed batch 64 of 99\n",
      "Processed batch 65 of 99\n",
      "Processed batch 66 of 99\n",
      "Processed batch 67 of 99\n",
      "Processed batch 68 of 99\n",
      "Processed batch 69 of 99\n",
      "Processed batch 70 of 99\n",
      "Processed batch 71 of 99\n",
      "Processed batch 72 of 99\n",
      "Processed batch 73 of 99\n",
      "Processed batch 74 of 99\n",
      "Processed batch 75 of 99\n",
      "Processed batch 76 of 99\n",
      "Processed batch 77 of 99\n",
      "Processed batch 78 of 99\n",
      "Processed batch 79 of 99\n",
      "Processed batch 80 of 99\n",
      "Processed batch 81 of 99\n",
      "Processed batch 82 of 99\n",
      "Processed batch 83 of 99\n",
      "Processed batch 84 of 99\n",
      "Processed batch 85 of 99\n",
      "Processed batch 86 of 99\n",
      "Processed batch 87 of 99\n",
      "Processed batch 88 of 99\n",
      "Processed batch 89 of 99\n",
      "Processed batch 90 of 99\n",
      "Processed batch 91 of 99\n",
      "Processed batch 92 of 99\n",
      "Processed batch 93 of 99\n",
      "Processed batch 94 of 99\n",
      "Processed batch 95 of 99\n",
      "Processed batch 96 of 99\n",
      "Processed batch 97 of 99\n",
      "Processed batch 98 of 99\n",
      "Processed batch 99 of 99\n",
      "Processed batch 100 of 99\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Function to send text to GPT-4 and receive sentiment tag (you need to implement this)\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def ask_gpt(text):\n",
    "    try:\n",
    "        # Sending the prompt to the ChatGPT model and getting the response\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",  # Adjust the model name as needed\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "                      {\"role\": \"user\", \"content\": text}]\n",
    "        )\n",
    "        # Returning the text of the response\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "def throttled_request(text, delay=5.0):\n",
    "    response = ask_gpt(text)\n",
    "    time.sleep(delay)\n",
    "    return response\n",
    "\n",
    "# Function to process a batch and append results to a CSV file\n",
    "def process_batch(df, batch_size, csv_file):\n",
    "    start = 0\n",
    "    while start < len(df):\n",
    "        end = min(start + batch_size, len(df))\n",
    "        batch = df.iloc[start:end].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "        batch['Sentiment_Tag_2'] = batch['Text'].apply(lambda text: throttled_request(f\"\"\"You will be presented with a Reddit message and your job is to provide in return a sentiment tag: choose either the “Positive” OR “Negative” OR “Unclear” tag but NOT several). \n",
    "Assess the sentiment of a Reddit message concerning shares, identified by company names or stock tickers. \n",
    "Focus exclusively on sentiments about the shares' performance, not the overall business performance. Evaluate the entire post. \n",
    "Classify the sentiment as 'Positive' for actions like buying calls, holding call options, or selling put options; \n",
    "'Negative' for buying puts, holding put options, or selling call options; \n",
    "and 'Unclear' for neutral, mixed, conflicting sentiments, or unclear mentions. \n",
    "Return back a tag with a sentiment concerning the shares. Choose tags ONLY from the list of tags provided above. \n",
    "Provide in response just a tag without an explanation.\n",
    "Message: {text}\"\"\"))\n",
    "        # Append batch results to CSV file\n",
    "        if start == 0:\n",
    "            batch.to_csv(csv_file, mode='w', header=True, index=False)  # Write mode with header for the first batch\n",
    "        else:\n",
    "            batch.to_csv(csv_file, mode='a', header=False, index=False)  # Append mode without header for subsequent batches\n",
    "        \n",
    "        start += batch_size\n",
    "        print(f\"Processed batch {start // batch_size} of {len(df) // batch_size}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 3  # Adjust this based on your needs\n",
    "csv_file = '../data/wsb_sentiment_results_check.csv'\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "process_batch(df_check, batch_size, csv_file)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-checking the chat GPT-4 ratings and comparing two GPT model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464, 7)\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "df_check_gpt4 = pd.read_csv('../data/wsb_sentiment_results_check.csv')\n",
    "print(df_check_gpt4.shape)\n",
    "# df = df.head(9)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 464 entries, 0 to 463\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               464 non-null    object\n",
      " 1   title            464 non-null    object\n",
      " 2   selftext         337 non-null    object\n",
      " 3   Text             464 non-null    object\n",
      " 4   token_count      464 non-null    int64 \n",
      " 5   Sentiment_Tag    464 non-null    object\n",
      " 6   Sentiment_Tag_2  464 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 25.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_check_gpt4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at the new ratings (see new column Sentriment_Tag_2),  anc comparing the output of two GPT models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>Text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>Sentiment_Tag</th>\n",
       "      <th>Sentiment_Tag_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>njizhs</td>\n",
       "      <td>When did this Subreddit become therapy?</td>\n",
       "      <td>I swear if I see one more “I invested in GME b...</td>\n",
       "      <td>When did this Subreddit become therapy?, I swe...</td>\n",
       "      <td>136</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>r3i8oq</td>\n",
       "      <td>Be prepared for a drawdown in pie stocks</td>\n",
       "      <td>Pi will be the next COVID variant.  When the p...</td>\n",
       "      <td>Be prepared for a drawdown in pie stocks, Pi w...</td>\n",
       "      <td>184</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>loiz1r</td>\n",
       "      <td>Buying long term puts on Netflix.</td>\n",
       "      <td>After having access to Netflix ( NFLX ) in Ame...</td>\n",
       "      <td>Buying long term puts on Netflix., After havin...</td>\n",
       "      <td>170</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>rs41ko</td>\n",
       "      <td>RobinHood - Sell jan23 puts?</td>\n",
       "      <td>A lot of hedge funds have jumped into Robinhoo...</td>\n",
       "      <td>RobinHood - Sell jan23 puts?, A lot of hedge f...</td>\n",
       "      <td>62</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>qthc16</td>\n",
       "      <td>Who's Shorting Rivian this week?</td>\n",
       "      <td>It's now well know that Rivian is going to hit...</td>\n",
       "      <td>Who's Shorting Rivian this week?, It's now wel...</td>\n",
       "      <td>128</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                     title  \\\n",
       "56   njizhs   When did this Subreddit become therapy?   \n",
       "294  r3i8oq  Be prepared for a drawdown in pie stocks   \n",
       "376  loiz1r         Buying long term puts on Netflix.   \n",
       "348  rs41ko              RobinHood - Sell jan23 puts?   \n",
       "139  qthc16          Who's Shorting Rivian this week?   \n",
       "\n",
       "                                              selftext  \\\n",
       "56   I swear if I see one more “I invested in GME b...   \n",
       "294  Pi will be the next COVID variant.  When the p...   \n",
       "376  After having access to Netflix ( NFLX ) in Ame...   \n",
       "348  A lot of hedge funds have jumped into Robinhoo...   \n",
       "139  It's now well know that Rivian is going to hit...   \n",
       "\n",
       "                                                  Text  token_count  \\\n",
       "56   When did this Subreddit become therapy?, I swe...          136   \n",
       "294  Be prepared for a drawdown in pie stocks, Pi w...          184   \n",
       "376  Buying long term puts on Netflix., After havin...          170   \n",
       "348  RobinHood - Sell jan23 puts?, A lot of hedge f...           62   \n",
       "139  Who's Shorting Rivian this week?, It's now wel...          128   \n",
       "\n",
       "    Sentiment_Tag Sentiment_Tag_2  \n",
       "56       Negative         Unclear  \n",
       "294      Negative        Negative  \n",
       "376      Negative        Negative  \n",
       "348      Negative        Positive  \n",
       "139      Negative        Negative  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check_gpt4.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment_Tag_2\n",
      "Negative    342\n",
      "Unclear      87\n",
      "Positive     35\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(464, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting frequency counts for 'Sentiment_Tag'\n",
    "tag_counts = df_check_gpt4['Sentiment_Tag_2'].value_counts()\n",
    "\n",
    "# Displaying the frequency counts\n",
    "print(tag_counts)\n",
    "df_check_gpt4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "342 rows weer rated as \"negative\" by both GPT models.  This is 74% of the starting number of rowsrated as negative by Chat GPT 3.5 (464 rows).  In 8% of cases Chat GPT 4 disagreed with the negative rating given by Chat GPT 3.5 and assigned \"positive\" rating to the text. \n",
    "\n",
    "**Conclusion**:  I will treat those instances where both Chat GPT models agree that the rating was \"negative\" as the additional \"ground truth\" for my model training.  This will be very helpful in training my models as this will help to address the deficit of negative ratings in the labelled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting rows where two GPT models disagree with each other. Keeping only those rows where both ratings are \"negative\"\n",
    "df_check_gpt4 = df_check_gpt4[df_check_gpt4['Sentiment_Tag_2'] != 'Unclear'].copy()\n",
    "df_check_gpt4 = df_check_gpt4[df_check_gpt4['Sentiment_Tag_2'] != 'Positive'].copy()\n",
    "df_check_gpt4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df_check_gpt4.to_csv('../data/reddit_gpt4_negative_only.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
