{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713e2b95",
   "metadata": {},
   "source": [
    "# Identifying Precise Forecasters on r/Wallstreetbets\n",
    "**BrainStation Data Science Bootcamp - Capstone Project**\n",
    "\n",
    "**Author: L Gavrilova**\n",
    "\n",
    "**Date: 6 November 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8905b9",
   "metadata": {},
   "source": [
    "# Notebook 2A - Labelled dataset - Text Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e991fd",
   "metadata": {},
   "source": [
    "## 2.0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebooks 2A and 2B are designed for text cleaning for the labelled dataset (Notebook 2A) and the reddit dataset (Notebook 2B).  \n",
    "\n",
    "In this notebook 2A I perform the following steps:\n",
    "\n",
    "1. I load the reddit dataset and perform the following text cleaning steps:\n",
    "\n",
    "* removing rows with missing values\n",
    "* removing empty spaces\n",
    "* correcting labels in the target column\n",
    "* removing website inks (urls), hashtags (#) and mentions (@)\n",
    "* the resulting dataset is then saved into a csv file.\n",
    "* I then do an additional cleaning step by removing and isolating emojis into a separate column.  This information can be useful during feature engineering steps, so I donâ€™t want to lose this indicator of sentiment. \n",
    "* Finally, slang words and emojis used inside the wallstreetbets community and not obvious to outsiders are replaced with normal English words and phrases. For that, I created a csv file names \"WSB dictionary\" where I mapped the WSB slang with corresponding common English words. \n",
    "\n",
    "The result is a csv file that is prepared for further machine learning techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f51324",
   "metadata": {},
   "source": [
    "### 2.1.1. Data Loading and Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3e553e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Regular Expressions Library\n",
    "import re\n",
    "\n",
    "# Emoji Handling Library\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/annotation file 3600 done 1142022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5020 entries, 0 to 5019\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   link_id    5001 non-null   object\n",
      " 1   parent_id  5001 non-null   object\n",
      " 2   User       5001 non-null   object\n",
      " 3   Text       5001 non-null   object\n",
      " 4   Intent     5001 non-null   object\n",
      " 5   Support    5001 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 235.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>t3_l6y2hy</td>\n",
       "      <td>t3_l6y2hy</td>\n",
       "      <td>MrStaraptor</td>\n",
       "      <td>Fuck Robinhood  \\nFuck D1 Capital  \\nFuck Melvin Capital  \\nFuck Wall Street  \\nFUCK EM ALL  \\nHOLD AMC, HOLD GME DON'T LET THE FIRE DIE OUT</td>\n",
       "      <td>u</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>t3_kwirha</td>\n",
       "      <td>t3_kwirha</td>\n",
       "      <td>Spanky_Stonks</td>\n",
       "      <td>Fuck yeah!  Melvin Capital can suck it ğŸ“ˆğŸš€ GME to the moon!! â˜„ï¸</td>\n",
       "      <td>u</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>t3_l8509l</td>\n",
       "      <td>t3_l8509l</td>\n",
       "      <td>Spicy_Yasuo</td>\n",
       "      <td>Dumbass question I know, but, where if even possible can I buy $gme? I cant find a single app that I have used in the past that is allowing gme trading atm.</td>\n",
       "      <td>y</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>t3_m5tffe</td>\n",
       "      <td>t1_gr2q3fj</td>\n",
       "      <td>FreshestCremeFraiche</td>\n",
       "      <td>GME</td>\n",
       "      <td>u</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>t3_lra5cg</td>\n",
       "      <td>t3_lra5cg</td>\n",
       "      <td>Jd562310</td>\n",
       "      <td>GME</td>\n",
       "      <td>u</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        link_id   parent_id                  User  \\\n",
       "63    t3_l6y2hy   t3_l6y2hy           MrStaraptor   \n",
       "1847  t3_kwirha   t3_kwirha         Spanky_Stonks   \n",
       "3900  t3_l8509l   t3_l8509l           Spicy_Yasuo   \n",
       "3795  t3_m5tffe  t1_gr2q3fj  FreshestCremeFraiche   \n",
       "4799  t3_lra5cg   t3_lra5cg              Jd562310   \n",
       "\n",
       "                                                                                                                                                              Text  \\\n",
       "63                    Fuck Robinhood  \\nFuck D1 Capital  \\nFuck Melvin Capital  \\nFuck Wall Street  \\nFUCK EM ALL  \\nHOLD AMC, HOLD GME DON'T LET THE FIRE DIE OUT   \n",
       "1847                                                                                                Fuck yeah!  Melvin Capital can suck it ğŸ“ˆğŸš€ GME to the moon!! â˜„ï¸   \n",
       "3900  Dumbass question I know, but, where if even possible can I buy $gme? I cant find a single app that I have used in the past that is allowing gme trading atm.   \n",
       "3795                                                                                                                                                           GME   \n",
       "4799                                                                                                                                                           GME   \n",
       "\n",
       "     Intent Support  \n",
       "63        u       y  \n",
       "1847      u       y  \n",
       "3900      y       u  \n",
       "3795      u       y  \n",
       "4799      u       y  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1948</td>\n",
       "      <td>3153</td>\n",
       "      <td>4662</td>\n",
       "      <td>4952</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>t3_ladzdt</td>\n",
       "      <td>t3_ladzdt</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>GME</td>\n",
       "      <td>u</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>3246</td>\n",
       "      <td>2473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          link_id  parent_id           User  Text Intent Support\n",
       "count        5001       5001           5001  5001   5001    5001\n",
       "unique       1948       3153           4662  4952      6       4\n",
       "top     t3_ladzdt  t3_ladzdt  AutoModerator   GME      u       y\n",
       "freq           66         46             14    22   3246    2473"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['link_id'].nunique() == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link_id      0.003785\n",
       "parent_id    0.003785\n",
       "User         0.003785\n",
       "Text         0.003785\n",
       "Intent       0.003785\n",
       "Support      0.003785\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     link_id parent_id User Text Intent Support\n",
       "5001     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5002     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5003     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5004     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5005     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5006     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5007     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5008     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5009     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5010     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5011     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5012     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5013     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5014     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5015     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5016     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5017     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5018     NaN       NaN  NaN  NaN    NaN     NaN\n",
       "5019     NaN       NaN  NaN  NaN    NaN     NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['Text'].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows that have NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [link_id, parent_id, User, Text, Intent, Support]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['Text'].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intent\n",
       "u     3246\n",
       "y      983\n",
       "m      370\n",
       "i      318\n",
       "n       83\n",
       " u       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent\n",
      "u    3247\n",
      "y     983\n",
      "m     370\n",
      "i     318\n",
      "n      83\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replacing ' u' with 'u' in the 'Intent' column\n",
    "df['Intent'] = df['Intent'].str.replace(' u', 'u', regex=False)\n",
    "# checking again:\n",
    "value_counts = df['Intent'].value_counts() \n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def purge_content(text):\n",
    "    text_without_urls = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text_without_hashtags = re.sub(r'#\\S+', '', text_without_urls)\n",
    "    text_without_mentions = re.sub(r'@\\S+', '', text_without_hashtags)\n",
    "    clean_text = re.sub(r'\\n+', ' ', text_without_mentions)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "for i in range(len(df_clean['Text'])):\n",
    "    df_clean['Text'][i] = purge_content(df_clean['Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>t3_l66caa</td>\n",
       "      <td>t1_gkyxvml</td>\n",
       "      <td>EllipticalOrbitMan</td>\n",
       "      <td></td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>t3_l0mc06</td>\n",
       "      <td>t1_gju8jei</td>\n",
       "      <td>wolfiasty</td>\n",
       "      <td></td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>t3_l6kqyk</td>\n",
       "      <td>t1_gl17oj6</td>\n",
       "      <td>EconomicallyLiterate</td>\n",
       "      <td></td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>t3_khq3x2</td>\n",
       "      <td>t1_ggo6fi4</td>\n",
       "      <td>JonBoy82</td>\n",
       "      <td></td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>t3_lat43j</td>\n",
       "      <td>t1_glq69gz</td>\n",
       "      <td>Free_Joty</td>\n",
       "      <td></td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        link_id   parent_id                  User Text Intent Support\n",
       "402   t3_l66caa  t1_gkyxvml    EllipticalOrbitMan           i       i\n",
       "1264  t3_l0mc06  t1_gju8jei             wolfiasty           i       i\n",
       "2187  t3_l6kqyk  t1_gl17oj6  EconomicallyLiterate           i       i\n",
       "4157  t3_khq3x2  t1_ggo6fi4              JonBoy82           i       i\n",
       "4265  t3_lat43j  t1_glq69gz             Free_Joty           i       i"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "df_clean[df_clean['Text'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where the 'Text' column is an empty string\n",
    "df_clean = df_clean[df_clean['Text'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording the cleaned dataset as a new csv file to be used in other notebooks:\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('../data/labelled_dataset_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b4226",
   "metadata": {},
   "source": [
    "### 2.1.2. Filtering out emojis by creating a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e983b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map emojis to their descriptions\n",
    "def emoji_description(emoji):\n",
    "    emoji_map = {\n",
    "        \"ğŸš€\": \" super optimistic, \",\n",
    "        \"ğŸ¦\": \" brotherhood, \",\n",
    "        \"ğŸ¤\": \" hope, \",\n",
    "        \"ğŸŒ™\": \" very optimistic, \",\n",
    "        \"ğŸŒ•\": \" very optimistic, \",\n",
    "        \"ğŸ’ğŸ¤šğŸ¼\": \" patient investors, \",\n",
    "        \"ğŸ’ğŸ–\": \" patient investors, \",\n",
    "        \"ğŸ’ğŸ™Œ\": \" patient investors, \",\n",
    "        \"ğŸ™Œ\": \" patient investors, \",\n",
    "        \"ğŸ’\": \" patient investors, \",\n",
    "        \"ğŸ§»ğŸ¤šğŸ¼\": \" impatient investors, \",\n",
    "        \"ğŸ§»ğŸ–\": \" impatient investors, \",\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "    # If the full emoji is in the map, return the description\n",
    "    if emoji in emoji_map:\n",
    "        return emoji_map[emoji]\n",
    "    # If not, split any combined emojis and look up their individual descriptions\n",
    "    else:\n",
    "        return ''.join([emoji_map.get(char, '') for char in emoji])  # Default to empty string if not in mapping\n",
    "\n",
    "def extract_and_replace_emojis(df, text_column_name='Text', emoji_column_name='emoji_text'):\n",
    "    # Initialize an empty column for extracted emojis if a column name is provided\n",
    "    if emoji_column_name:\n",
    "        df[emoji_column_name] = ''\n",
    "\n",
    "    # Function to extract and replace emojis in a text\n",
    "    def process_text(text):\n",
    "        emoji_pattern = re.compile(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FB00-\\U0001FBFF\\U0001F004]+')\n",
    "\n",
    "        # Find all emojis in the text using the regex pattern\n",
    "        emoji_matches = emoji_pattern.findall(text)\n",
    "        emojis_extracted = ''\n",
    "        text_with_replaced_emojis = text\n",
    "\n",
    "        # Iterate over the found emojis\n",
    "        for emoji_str in emoji_matches:\n",
    "            # For each emoji in the emoji string\n",
    "            for emoji_char in emoji_str:\n",
    "                emoji_desc = emoji_description(emoji_char)  # Get description for individual emoji\n",
    "                text_with_replaced_emojis = text_with_replaced_emojis.replace(emoji_char, emoji_desc, 1)\n",
    "                emojis_extracted += emoji_char + ' '  # Add space to separate emojis\n",
    "\n",
    "        # Return the modified text and the extracted emojis\n",
    "        return text_with_replaced_emojis, emojis_extracted.strip()\n",
    "\n",
    "    # Apply the processing function to the specified column and create new columns for text and emojis\n",
    "    result = df[text_column_name].apply(process_text)\n",
    "    df[text_column_name] = result.apply(lambda x: x[0])\n",
    "    \n",
    "    if emoji_column_name:\n",
    "        df[emoji_column_name] = result.apply(lambda x: x[1])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7c98bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to extract and replace emojis from 'Text' column\n",
    "df_clean = extract_and_replace_emojis(df_clean, text_column_name='Text', emoji_column_name='emoji_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4be45fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emoji_text\n",
       "                                                                     4254\n",
       "ğŸš€ ğŸš€ ğŸš€                                                                  66\n",
       "ğŸš€                                                                      50\n",
       "ğŸš€ ğŸš€                                                                    28\n",
       "ğŸš€ ğŸš€ ğŸš€ ğŸš€                                                                26\n",
       "                                                                     ... \n",
       "ğŸ§» ğŸ¤š ğŸ¼ ğŸ§» ğŸ¤š ğŸ¼ ğŸ§» ğŸ¤š ğŸ¼ ğŸ§» ğŸ¤š ğŸ¼ ğŸ’ ğŸ¤š ğŸ¼ ğŸ’ ğŸ¤š ğŸ¼ ğŸ’ ğŸ¤š ğŸ¼ ğŸ’ ğŸ¤š ğŸ¼ ğŸ’ ğŸš€ ğŸš€ ğŸš€ ğŸš€ ğŸš€ ğŸš€ ğŸš€ ğŸš€       1\n",
       "ğŸ’ ğŸš€ ğŸš€ ğŸŒ™                                                                 1\n",
       "ğŸš€ ğŸ’ª ğŸ‹ ğŸ’                                                                 1\n",
       "ğŸ“ ğŸ‘‹ ğŸ’ ğŸ‘ ğŸš€ ğŸš€ ğŸš€ ğŸŒˆ ğŸ» ğŸ“‰ ğŸš€ ğŸš€ ğŸš€ ğŸŒ• ğŸ”¥ ğŸ”¥                                         1\n",
       "ğŸš€ ğŸš€ ğŸš€ ğŸ– ğŸ’ ğŸ– ğŸ’µ ğŸ– ğŸ¿ ğŸ— ğŸš€ ğŸ¦ ğŸŒš ğŸš€ ğŸš€                                           1\n",
       "Name: count, Length: 383, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the new column with emojis extracted from the text\n",
    "df_clean.sample().T\n",
    "df_clean['emoji_text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Support</th>\n",
       "      <th>emoji_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>t3_kwe7q7</td>\n",
       "      <td>t1_gj5gnv5</td>\n",
       "      <td>rustyham</td>\n",
       "      <td>GME. Friday a bunch of puts will be exercised and price goes up more</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>t3_l6er79</td>\n",
       "      <td>t1_gl0b033</td>\n",
       "      <td>raahiv</td>\n",
       "      <td>Pretty sure they blocked GME and AMC</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>t3_l8fqua</td>\n",
       "      <td>t1_glcdrl4</td>\n",
       "      <td>Vicous</td>\n",
       "      <td>Honestly. I know GameStop has been a joke for quite some time but I feel like they've taken their lumps and they can turn things around. And I hope they do because I've met some really nice people at their stores and it's suck to see them all lose their jobs.  GameStop should consider being gaming lounges rather than pure retailers and even during this pandemic I bet that'd be damn popular. It'd be like your local comic shop but with the ability to truly deck their stores out with official game and pop culture merch and throw in some sponsored game tournaments, like, some Super Nintendo Land / Pokemon Center shit mixed with a coffee-shop-like setting. Since now we all technically own so much of the company, we may as well be on the board of directors and rally behind this.  So yeah, I like this stock.</td>\n",
       "      <td>u</td>\n",
       "      <td>y</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        link_id   parent_id      User  \\\n",
       "823   t3_kwe7q7  t1_gj5gnv5  rustyham   \n",
       "3714  t3_l6er79  t1_gl0b033    raahiv   \n",
       "631   t3_l8fqua  t1_glcdrl4    Vicous   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Text  \\\n",
       "823                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           GME. Friday a bunch of puts will be exercised and price goes up more   \n",
       "3714                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Pretty sure they blocked GME and AMC   \n",
       "631   Honestly. I know GameStop has been a joke for quite some time but I feel like they've taken their lumps and they can turn things around. And I hope they do because I've met some really nice people at their stores and it's suck to see them all lose their jobs.  GameStop should consider being gaming lounges rather than pure retailers and even during this pandemic I bet that'd be damn popular. It'd be like your local comic shop but with the ability to truly deck their stores out with official game and pop culture merch and throw in some sponsored game tournaments, like, some Super Nintendo Land / Pokemon Center shit mixed with a coffee-shop-like setting. Since now we all technically own so much of the company, we may as well be on the board of directors and rally behind this.  So yeah, I like this stock.   \n",
       "\n",
       "     Intent Support emoji_text  \n",
       "823       u       u             \n",
       "3714      u       u             \n",
       "631       u       y             "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Replacing WSB slang with custom made \"WSB Dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WSB lingo dictionary\n",
    "wsb_dict_df = pd.read_csv('../data/WSB_dictionary.csv')\n",
    "\n",
    "# Convert the DataFrame to a dictionary\n",
    "wsb_dict = dict(zip(wsb_dict_df['WSB lingo'], wsb_dict_df['English']))\n",
    "\n",
    "# Function to replace WSB lingo with English\n",
    "def replace_wsb_lingo(text):\n",
    "    # Use a regex pattern to match only whole words\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(key) for key in wsb_dict.keys()) + r')\\b'\n",
    "    # Replace occurrences of each lingo with the English equivalent\n",
    "    return re.sub(pattern, lambda x: wsb_dict[x.group()], text)\n",
    "\n",
    "# Apply the function to the 'Text' column\n",
    "df_clean['Text'] = df_clean['Text'].apply(replace_wsb_lingo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Examples of texts before and after the cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_id                                                                                                                                                                                                                                                                                                                                             t3_l6cb1x\n",
      "parent_id                                                                                                                                                                                                                                                                                                                                           t3_l6cb1x\n",
      "User                                                                                                                                                                                                                                                                                                                                     nights_that_say_knee\n",
      "Text         ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘ğŸ’ğŸ‘\\n\\nBUY ğŸš€ğŸš€ GME ğŸš€ğŸš€ to get your ğŸŸï¸ğŸŸï¸ğŸŒ•lğŸŒ\\n\\nAIN'T NO LIE BABY ğŸ‘¶, ğŸ’°BUY, ğŸ¤‘ BUY, ğŸ’µ BUY!\n",
      "Intent                                                                                                                                                                                                                                                                                                                                                      u\n",
      "Support                                                                                                                                                                                                                                                                                                                                                     y\n",
      "Name: 2026, dtype: object\n",
      "link_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       t3_l6cb1x\n",
      "parent_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     t3_l6cb1x\n",
      "User                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               nights_that_say_knee\n",
      "Text           patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  patient investors,  BUY  super optimistic,  super optimistic,  GME  super optimistic,  super optimistic,  to get your ï¸ï¸ very optimistic, l AIN'T NO LIE BABY , BUY,  BUY,  BUY!\n",
      "Intent                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                u\n",
      "Support                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               y\n",
      "emoji_text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸ’ ğŸ‘ ğŸš€ ğŸš€ ğŸš€ ğŸš€ ğŸŸ ğŸŸ ğŸŒ• ğŸŒ ğŸ‘¶ ğŸ’° ğŸ¤‘ ğŸ’µ\n",
      "Name: 2026, dtype: object\n"
     ]
    }
   ],
   "source": [
    "original_with_index = df.loc[2026]\n",
    "print(original_with_index)\n",
    "\n",
    "clean_with_index = df_clean.loc[2026]\n",
    "print(clean_with_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_id                                            t3_l8ynt4\n",
      "parent_id                                          t3_l8ynt4\n",
      "User                                       wowexcellentstuff\n",
      "Text         did NOT read. $GME to mf Andromeda ğŸš€ğŸš€ğŸš€ğŸŒŒğŸŒŒ\\n\\nğŸ’ğŸ¤²ğŸ’\n",
      "Intent                                                     u\n",
      "Support                                                    y\n",
      "Name: 3986, dtype: object\n",
      "link_id                                                                                                                                   t3_l8ynt4\n",
      "parent_id                                                                                                                                 t3_l8ynt4\n",
      "User                                                                                                                              wowexcellentstuff\n",
      "Text          did NOT read. $GME to mf Andromeda  super optimistic,  super optimistic,  super optimistic,   patient investors,  patient investors, \n",
      "Intent                                                                                                                                            u\n",
      "Support                                                                                                                                           y\n",
      "emoji_text                                                                                                                          ğŸš€ ğŸš€ ğŸš€ ğŸŒŒ ğŸŒŒ ğŸ’ ğŸ¤² ğŸ’\n",
      "Name: 3986, dtype: object\n"
     ]
    }
   ],
   "source": [
    "original_with_index = df.loc[3986]\n",
    "print(original_with_index)\n",
    "\n",
    "clean_with_index = df_clean.loc[3986]\n",
    "print(clean_with_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_id                                    t3_kkwy50\n",
      "parent_id                                  t3_kkwy50\n",
      "User                                SnooMacarons1548\n",
      "Text         GMEğŸš€ğŸš€ğŸš€\\n\\nIt's a money printing company\n",
      "Intent                                             u\n",
      "Support                                            y\n",
      "Name: 3386, dtype: object\n",
      "link_id                                                                                        t3_kkwy50\n",
      "parent_id                                                                                      t3_kkwy50\n",
      "User                                                                                    SnooMacarons1548\n",
      "Text          GME super optimistic,  super optimistic,  super optimistic,  It's a money printing company\n",
      "Intent                                                                                                 u\n",
      "Support                                                                                                y\n",
      "emoji_text                                                                                         ğŸš€ ğŸš€ ğŸš€\n",
      "Name: 3386, dtype: object\n"
     ]
    }
   ],
   "source": [
    "original_with_index = df.loc[3386]\n",
    "print(original_with_index)\n",
    "\n",
    "clean_with_index = df_clean.loc[3386]\n",
    "print(clean_with_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d8ec9",
   "metadata": {},
   "source": [
    "## 2.2. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording the cleaned dataset as a new csv file to be used in further steps:\n",
    "# Save the DataFrame to a CSV file\n",
    "df_clean.to_csv('../data/labelled_dataset_wo_emoji.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
